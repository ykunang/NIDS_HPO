{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Intrusion Detection with Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" #model will be trained on GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\Talos\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "Intel(R) Data Analytics Acceleration Library (Intel(R) DAAL) solvers for sklearn enabled: https://intelpython.github.io/daal4py/sklearn.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_matrices(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        A = np.load(f)\n",
    "        B = np.load(f)\n",
    "        C = np.load(f)\n",
    "        D = np.load(f)\n",
    "        E = np.load(f)\n",
    "        F = np.load(f)\n",
    "    return (A,B,C,D,E,F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_file =  '../CIDS-2018/10data2.npy'\n",
    "train,test,y_train,y_test,ylabel_train, ylabel_test = load_matrices(my_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "#from keras.layers import Dense, Activation, Merge, Reshape, Dropout\n",
    "from keras.layers import Activation, Reshape, Input, Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.activations import elu\n",
    "from keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import talos as ta\n",
    "import wrangle as wr\n",
    "from talos.metrics.keras_metrics import fmeasure_acc\n",
    "from talos import live\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selu(x):\n",
    "    \"\"\"Scaled Exponential Linear Unit. (Klambauer et al., 2017)\n",
    "    # Arguments\n",
    "        x: A tensor or variable to compute the activation function for.\n",
    "    # References\n",
    "        - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n",
    "    \"\"\"\n",
    "    alpha = 1.6732632423543772848170429916717\n",
    "    scale = 1.0507009873554804934193349852946\n",
    "    return scale * elu(x, alpha)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#actvation leakyrelu\n",
    "LR= LeakyReLU(0.01)\n",
    "LR.__name__ = 'lrelu'\n",
    "#actvation prelu\n",
    "#PR= PReLU(init='zero', weights=None)\n",
    "#PR.__name__ = 'prelu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath_ae=\"./logtalos/taloslr_fc_weights_a.hdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_file_name1(first_neuron,second_neuron,batch_size,kernel_initial,lr,activation):\n",
    "    \n",
    "    if activation==LR:\n",
    "       activation= 'lrelu'\n",
    "    \n",
    "    if activation==PReLU:\n",
    "       activation= 'prelu'\n",
    "    \n",
    "    if activation==relu:\n",
    "       activation= 'relu'\n",
    "    \n",
    "    if activation==elu:\n",
    "       activation= 'elu'\n",
    "    \n",
    "    if activation==selu:\n",
    "       activation= 'selu'\n",
    "\n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./logtalos/log3LR/neuron1_{0}-neuron2_{1}-batch{2}-kernelinit_{3}-lr{4}-activ_{5}.hdf\"\n",
    "    log_file = s.format(first_neuron,second_neuron,batch_size,kernel_initial,lr,activation)\n",
    "    return log_file\n",
    "\n",
    "def log_file_name2(first_neuron,second_neuron,batch_size,kernel_initial,lr,activation):\n",
    "    \n",
    "    if activation==LR:\n",
    "       activation= 'lrelu'\n",
    "    \n",
    "    if activation==PReLU:\n",
    "       activation= 'prelu'\n",
    "    \n",
    "    if activation==relu:\n",
    "       activation= 'relu'\n",
    "    \n",
    "    if activation==elu:\n",
    "       activation= 'elu'\n",
    "    \n",
    "    if activation==selu:\n",
    "       activation= 'selu'\n",
    "    \n",
    "    # The dir-name for the TensorBoard log-dir.\n",
    "    s = \"./logtalos/log3LR/neuron1_{0}-neuron2_{1}-batch{2}-kernelinit_{3}-lr{4}-activ_{5}.csv\"\n",
    "    log_file = s.format(first_neuron,second_neuron,batch_size,kernel_initial,lr,activation)\n",
    "    return log_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"./logtalos/3layer_tes_lr.best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we have to make sure to input data and params into the function\n",
    "# add input parameters to the function\n",
    "def dnn(x_train, ylabel_train, x_val, y_val, params):\n",
    "\n",
    "    input_dim = x_train.shape[1]\n",
    "\n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    \n",
    "    first_neuron=params['first_neuron']\n",
    "    second_neuron=params['second_neuron']\n",
    "    batch_size=params['batch_size']\n",
    "    kernel_initial=params['kernel_initializer']\n",
    "    lr=params['lr']\n",
    "    activation=params['activation']\n",
    "    \n",
    "    print('activation=',activation)\n",
    "    \n",
    "    log_file1 = log_file_name1(first_neuron,second_neuron,batch_size,kernel_initial,lr,activation)\n",
    "    checkpoint2 = ModelCheckpoint(log_file1, monitor='acc', save_best_only=True, mode='max')\n",
    "\n",
    "    \n",
    "    log_file2 = log_file_name2(first_neuron,second_neuron,batch_size,kernel_initial,lr,activation)\n",
    "\n",
    "    csv_logger2 = CSVLogger(log_file2,separator=',', append=False)\n",
    "    callbacks_list2 = [checkpoint2,csv_logger2]\n",
    "    \n",
    "    ###AE\n",
    "    \n",
    "    # replace the hyperparameter inputs with references to params dictionary \n",
    "    autoencoder = Sequential()\n",
    "    #encoder\n",
    "    \n",
    "    if activation==PReLU: \n",
    "        autoencoder.add(Dense(first_neuron, input_shape=(input_dim,), kernel_initializer=kernel_initial))\n",
    "        autoencoder.add(PReLU())\n",
    "        autoencoder.add(Dense(second_neuron, kernel_initializer=kernel_initial))\n",
    "        autoencoder.add(PReLU())\n",
    "                   \n",
    "        #decoder\n",
    "        #model.add(Dense(8, activation=params['activation']))\n",
    "        autoencoder.add(Dense(first_neuron, kernel_initializer=kernel_initial))\n",
    "        autoencoder.add(PReLU())\n",
    "        autoencoder.add(Dense(input_dim, activation='sigmoid', kernel_initializer=kernel_initial))\n",
    "        \n",
    "    else:\n",
    "        autoencoder.add(Dense(first_neuron, input_shape=(input_dim,), activation=activation, kernel_initializer=kernel_initial))\n",
    "        autoencoder.add(Dense(second_neuron, activation=activation, kernel_initializer=kernel_initial))\n",
    "        #decoder\n",
    "        #model.add(Dense(8, activation=params['activation']))\n",
    "        autoencoder.add(Dense(first_neuron, activation=activation, kernel_initializer=kernel_initial))\n",
    "        autoencoder.add(Dense(input_dim, activation='sigmoid', kernel_initializer=kernel_initial))\n",
    "    \n",
    "    #model = multi_gpu_model(model, gpus=1)\n",
    "    autoencoder.summary()\n",
    "    print(input_dim)\n",
    "    \n",
    "    input_img = Input(shape=(input_dim,))\n",
    "    encoder_layer1 = autoencoder.layers[0]\n",
    "    encoder_layer2 = autoencoder.layers[1]\n",
    "    encoder = Model(input_img, encoder_layer2(encoder_layer1(input_img)))\n",
    "    \n",
    "    #encoder_layer1 = autoencoder.layers[0]\n",
    "    #encoder_layer2 = autoencoder.layers[1]\n",
    "    #encoder_layer3 = autoencoder.layers[2]\n",
    "    #encoder = Model(input_img, encoder_layer3(encoder_layer2(encoder_layer1(input_img))))\n",
    "    encoder.summary()\n",
    "\n",
    "    \n",
    "    autoencoder.compile(loss='mse', optimizer='adam', metrics=['acc'])\n",
    "    #model.compile(loss=params['losses'],\n",
    "    #              optimizer=params['optimizer'](),\n",
    "    #              metrics=['acc', fmeasure_acc])\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    history=autoencoder.fit(x,x,\n",
    "                             epochs=params['epochs'],\n",
    "                             batch_size=batch_size,\n",
    "                              #shuffle=True,\n",
    "                              validation_split=0.2,\n",
    "                              callbacks=callbacks_list,                    \n",
    "                             #callbacks=[early_stopping])\n",
    "                              #validation_data=(test,test),\n",
    "                              verbose=1)\n",
    "  \n",
    "\n",
    "    num_classes=15\n",
    "    out2 = Dense(num_classes, activation='softmax',kernel_initializer=kernel_initial)(encoder.output)\n",
    "    newmodel = Model(encoder.input,out2)\n",
    "    \n",
    "   \n",
    "    newmodel.compile(loss='categorical_crossentropy', \n",
    "                     #optimizer='adam', \n",
    "                     optimizer= Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08,decay=0.0, amsgrad=False),\n",
    "                     metrics=['acc']) \n",
    "    newmodel.summary()\n",
    "\n",
    "\n",
    "    history2a=newmodel.fit(x, y,\n",
    "                           epochs=params['epochs2'],\n",
    "                           batch_size=batch_size,\n",
    "                           validation_split=0.2,\n",
    "                           callbacks=callbacks_list2,\n",
    "                           #callbacks=[early_stopping],\n",
    "                           #validation_data=(test,ylabel_test),\n",
    "                           verbose=1)\n",
    "\n",
    "    \n",
    "    del encoder\n",
    "    del autoencoder\n",
    "    #del dnn_model\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    return history2a, newmodel #, encoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we can go ahead and set the parameter space\n",
    "p = {'first_neuron':[70, 60, 50],\n",
    "     'second_neuron':[35,30,25,20],\n",
    "     'batch_size': [32,64,256],\n",
    "     'epochs': [20],\n",
    "     'epochs2': [30],\n",
    "     'dropout': [0],\n",
    "     'kernel_initializer': ['lecun_uniform','lecun_normal','he_normal','he_uniform','normal','glorot_uniform','glorot_normal'],\n",
    "     'optimizer': [Adam],\n",
    "     'lr':[0.1,0.01, 0.001,0.0001],#0.00001],\n",
    "     'activation':[relu, elu,selu, LR, PReLU]}\n",
    "     #'activation':[LR]}#, PReLU ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session, clear_session\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train\n",
    "y=ylabel_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1619315, 80)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1619315, 15)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/40 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 80)                4080      \n",
      "=================================================================\n",
      "Total params: 10,705\n",
      "Trainable params: 10,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                1275      \n",
      "=================================================================\n",
      "Total params: 5,325\n",
      "Trainable params: 5,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0015 - acc: 0.2587 - val_loss: 2.5968e-04 - val_acc: 0.3760\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 1.4735e-04 - acc: 0.3117 - val_loss: 1.7896e-04 - val_acc: 0.3156\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 2.8361e-05 - acc: 0.3085 - val_loss: 1.4208e-04 - val_acc: 0.2845\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 2.4169e-05 - acc: 0.3125 - val_loss: 1.3334e-04 - val_acc: 0.3100\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 2.2036e-05 - acc: 0.2974 - val_loss: 1.3426e-04 - val_acc: 0.2749\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 1.8497e-05 - acc: 0.2797 - val_loss: 1.2043e-04 - val_acc: 0.2768\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.5970e-05 - acc: 0.2401 - val_loss: 1.1120e-04 - val_acc: 0.2674\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.5306e-05 - acc: 0.2539 - val_loss: 1.1908e-04 - val_acc: 0.2758\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.4781e-05 - acc: 0.2760 - val_loss: 1.0745e-04 - val_acc: 0.2747\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.4637e-05 - acc: 0.2774 - val_loss: 1.1365e-04 - val_acc: 0.5077\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.4486e-05 - acc: 0.3095 - val_loss: 1.2370e-04 - val_acc: 0.4635\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.4097e-05 - acc: 0.4256 - val_loss: 1.1907e-04 - val_acc: 0.3500\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.3849e-05 - acc: 0.3724 - val_loss: 1.0906e-04 - val_acc: 0.5246\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.3799e-05 - acc: 0.4921 - val_loss: 1.1214e-04 - val_acc: 0.5850\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.3696e-05 - acc: 0.5045 - val_loss: 1.1057e-04 - val_acc: 0.6311\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.3378e-05 - acc: 0.3780 - val_loss: 1.3628e-04 - val_acc: 0.4504\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 124s 95us/step - loss: 1.3400e-05 - acc: 0.4675 - val_loss: 1.0429e-04 - val_acc: 0.3154\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 123s 95us/step - loss: 1.3437e-05 - acc: 0.4633 - val_loss: 1.0704e-04 - val_acc: 0.3288\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 123s 95us/step - loss: 1.3515e-05 - acc: 0.5049 - val_loss: 1.0450e-04 - val_acc: 0.6000\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 123s 95us/step - loss: 1.3166e-05 - acc: 0.4591 - val_loss: 1.3534e-04 - val_acc: 0.3236\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 5,715\n",
      "Trainable params: 5,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 123s 95us/step - loss: 0.1746 - acc: 0.9400 - val_loss: 2.4612 - val_acc: 0.8452\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 124s 95us/step - loss: 0.0530 - acc: 0.9737 - val_loss: 2.4536 - val_acc: 0.8462\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 124s 95us/step - loss: 0.0494 - acc: 0.9745 - val_loss: 2.4535 - val_acc: 0.8463\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 123s 95us/step - loss: 0.0479 - acc: 0.9750 - val_loss: 2.4521 - val_acc: 0.8466\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 123s 95us/step - loss: 0.0470 - acc: 0.9752 - val_loss: 2.4509 - val_acc: 0.8469\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 123s 95us/step - loss: 0.0464 - acc: 0.9754 - val_loss: 2.4498 - val_acc: 0.8471\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.0460 - acc: 0.9755 - val_loss: 2.4497 - val_acc: 0.8467\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0457 - acc: 0.9755 - val_loss: 2.4498 - val_acc: 0.8472\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0454 - acc: 0.9756 - val_loss: 2.4488 - val_acc: 0.8473\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0452 - acc: 0.9757 - val_loss: 2.4493 - val_acc: 0.8469\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0450 - acc: 0.9757 - val_loss: 2.4486 - val_acc: 0.8474\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0448 - acc: 0.9758 - val_loss: 2.4473 - val_acc: 0.8477\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0447 - acc: 0.9758 - val_loss: 2.4487 - val_acc: 0.8474\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0445 - acc: 0.9760 - val_loss: 2.4475 - val_acc: 0.8476\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0445 - acc: 0.9760 - val_loss: 2.4476 - val_acc: 0.8477\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.0444 - acc: 0.9761 - val_loss: 2.4474 - val_acc: 0.8477\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.0442 - acc: 0.9762 - val_loss: 2.4470 - val_acc: 0.8478\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0441 - acc: 0.9762 - val_loss: 2.4475 - val_acc: 0.8477\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0440 - acc: 0.9763 - val_loss: 2.4481 - val_acc: 0.8473\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0440 - acc: 0.9764 - val_loss: 2.4468 - val_acc: 0.8478\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0439 - acc: 0.9765 - val_loss: 2.4483 - val_acc: 0.8475\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0438 - acc: 0.9765 - val_loss: 2.4476 - val_acc: 0.8477\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0437 - acc: 0.9766 - val_loss: 2.4482 - val_acc: 0.8470\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0437 - acc: 0.9766 - val_loss: 2.4476 - val_acc: 0.8476\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0436 - acc: 0.9767 - val_loss: 2.4481 - val_acc: 0.8474\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0436 - acc: 0.9766 - val_loss: 2.4475 - val_acc: 0.8478\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0435 - acc: 0.9766 - val_loss: 2.4479 - val_acc: 0.8476\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0435 - acc: 0.9767 - val_loss: 2.4477 - val_acc: 0.8476\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0435 - acc: 0.9768 - val_loss: 2.4470 - val_acc: 0.8477\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0434 - acc: 0.9767 - val_loss: 2.4493 - val_acc: 0.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 1/40 [1:41:39<66:04:41, 6099.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4080      \n",
      "=================================================================\n",
      "Total params: 10,200\n",
      "Trainable params: 10,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "=================================================================\n",
      "Total params: 5,070\n",
      "Trainable params: 5,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 4.8655e-04 - acc: 0.2178 - val_loss: 1.7124e-04 - val_acc: 0.2668\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 3.0992e-05 - acc: 0.1901 - val_loss: 1.5945e-04 - val_acc: 0.2489\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 2.4948e-05 - acc: 0.1875 - val_loss: 1.4366e-04 - val_acc: 0.2467\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 2.1933e-05 - acc: 0.2024 - val_loss: 1.7166e-04 - val_acc: 0.3233\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 2.0534e-05 - acc: 0.2379 - val_loss: 1.4742e-04 - val_acc: 0.3290\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 1.9031e-05 - acc: 0.3487 - val_loss: 1.1864e-04 - val_acc: 0.3647\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.8094e-05 - acc: 0.3665 - val_loss: 1.5243e-04 - val_acc: 0.2836\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 117s 91us/step - loss: 1.7622e-05 - acc: 0.4029 - val_loss: 1.3021e-04 - val_acc: 0.5016\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.6641e-05 - acc: 0.3978 - val_loss: 1.3412e-04 - val_acc: 0.3565\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.6493e-05 - acc: 0.3748 - val_loss: 1.4199e-04 - val_acc: 0.3639\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.6028e-05 - acc: 0.4426 - val_loss: 1.4279e-04 - val_acc: 0.3648\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 1.5675e-05 - acc: 0.4544 - val_loss: 1.3845e-04 - val_acc: 0.4144\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 1.5596e-05 - acc: 0.4569 - val_loss: 1.4305e-04 - val_acc: 0.5310\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.6311e-05 - acc: 0.4810 - val_loss: 1.4710e-04 - val_acc: 0.4209\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.5410e-05 - acc: 0.5404 - val_loss: 1.2764e-04 - val_acc: 0.6936\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.5041e-05 - acc: 0.5337 - val_loss: 1.3095e-04 - val_acc: 0.4202\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 1.4796e-05 - acc: 0.4711 - val_loss: 1.5374e-04 - val_acc: 0.3979\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 1.4761e-05 - acc: 0.4662 - val_loss: 1.4696e-04 - val_acc: 0.4058\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.4437e-05 - acc: 0.5355 - val_loss: 1.5094e-04 - val_acc: 0.3737\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.4213e-05 - acc: 0.5756 - val_loss: 1.2827e-04 - val_acc: 0.6593\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 5,385\n",
      "Trainable params: 5,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0680 - acc: 0.9692 - val_loss: 2.4488 - val_acc: 0.8473\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0460 - acc: 0.9753 - val_loss: 2.4484 - val_acc: 0.8474\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 0.0452 - acc: 0.9758 - val_loss: 2.4481 - val_acc: 0.8476\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0447 - acc: 0.9762 - val_loss: 2.4477 - val_acc: 0.8476\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0444 - acc: 0.9764 - val_loss: 2.4473 - val_acc: 0.8477\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0441 - acc: 0.9768 - val_loss: 2.4459 - val_acc: 0.8480\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0439 - acc: 0.9769 - val_loss: 2.4476 - val_acc: 0.8474\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0438 - acc: 0.9769 - val_loss: 2.4469 - val_acc: 0.8478\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0434 - acc: 0.9773 - val_loss: 2.4478 - val_acc: 0.8474\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0432 - acc: 0.9773 - val_loss: 2.4480 - val_acc: 0.8472\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0432 - acc: 0.9774 - val_loss: 2.4470 - val_acc: 0.8479\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0430 - acc: 0.9775 - val_loss: 2.4481 - val_acc: 0.8479\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0428 - acc: 0.9776 - val_loss: 2.4468 - val_acc: 0.8480\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0428 - acc: 0.9775 - val_loss: 2.4476 - val_acc: 0.8474\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 117s 91us/step - loss: 0.0427 - acc: 0.9776 - val_loss: 2.4469 - val_acc: 0.8480\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0427 - acc: 0.9776 - val_loss: 2.4466 - val_acc: 0.8479\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0428 - acc: 0.9775 - val_loss: 2.4474 - val_acc: 0.8479\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0426 - acc: 0.9776 - val_loss: 2.4461 - val_acc: 0.8480\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0426 - acc: 0.9776 - val_loss: 2.4468 - val_acc: 0.8476\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 116s 89us/step - loss: 0.0439 - acc: 0.9776 - val_loss: 2.4461 - val_acc: 0.8480\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 117s 91us/step - loss: 0.0430 - acc: 0.9777 - val_loss: 2.4473 - val_acc: 0.8478\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0425 - acc: 0.9776 - val_loss: 2.4467 - val_acc: 0.8479\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0424 - acc: 0.9777 - val_loss: 2.4467 - val_acc: 0.8480\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0428 - acc: 0.9777 - val_loss: 2.4458 - val_acc: 0.8481\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 117s 91us/step - loss: 0.0425 - acc: 0.9777 - val_loss: 2.4459 - val_acc: 0.8481\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0427 - acc: 0.9777 - val_loss: 2.4478 - val_acc: 0.8470\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0426 - acc: 0.9777 - val_loss: 2.4464 - val_acc: 0.8480\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0423 - acc: 0.9778 - val_loss: 2.4463 - val_acc: 0.8479\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0432 - acc: 0.9777 - val_loss: 2.4459 - val_acc: 0.8480\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0445 - acc: 0.9775 - val_loss: 2.4490 - val_acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▌         | 2/40 [3:20:37<63:52:20, 6051.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                2160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4880      \n",
      "=================================================================\n",
      "Total params: 14,035\n",
      "Trainable params: 14,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "=================================================================\n",
      "Total params: 6,995\n",
      "Trainable params: 6,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0017 - acc: 0.2645 - val_loss: 2.4740e-04 - val_acc: 0.2573\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.7317e-05 - acc: 0.2110 - val_loss: 1.6749e-04 - val_acc: 0.2551\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 2.1469e-05 - acc: 0.2128 - val_loss: 1.5076e-04 - val_acc: 0.2569\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 1.7440e-05 - acc: 0.2121 - val_loss: 1.5033e-04 - val_acc: 0.2527\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.5813e-05 - acc: 0.2189 - val_loss: 1.4248e-04 - val_acc: 0.2548\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.4815e-05 - acc: 0.2169 - val_loss: 1.4599e-04 - val_acc: 0.2939\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.3677e-05 - acc: 0.2376 - val_loss: 1.4623e-04 - val_acc: 0.2850\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 1.3400e-05 - acc: 0.2203 - val_loss: 1.3372e-04 - val_acc: 0.2564\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.2724e-05 - acc: 0.2083 - val_loss: 1.3060e-04 - val_acc: 0.2666\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 1.2459e-05 - acc: 0.2127 - val_loss: 1.3276e-04 - val_acc: 0.2585\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.2397e-05 - acc: 0.2601 - val_loss: 1.3490e-04 - val_acc: 0.2543\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.2005e-05 - acc: 0.2427 - val_loss: 1.3901e-04 - val_acc: 0.2776\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.2232e-05 - acc: 0.2873 - val_loss: 1.1996e-04 - val_acc: 0.2654\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.1825e-05 - acc: 0.2495 - val_loss: 1.4258e-04 - val_acc: 0.3088\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.1694e-05 - acc: 0.2702 - val_loss: 1.3952e-04 - val_acc: 0.3146\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 1.1371e-05 - acc: 0.2764 - val_loss: 1.3331e-04 - val_acc: 0.2986\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.1212e-05 - acc: 0.2772 - val_loss: 1.3774e-04 - val_acc: 0.3497\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 1.1465e-05 - acc: 0.2921 - val_loss: 1.2746e-04 - val_acc: 0.3611\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.0981e-05 - acc: 0.2694 - val_loss: 1.1991e-04 - val_acc: 0.2989\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.1487e-05 - acc: 0.3345 - val_loss: 1.2066e-04 - val_acc: 0.3049\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                540       \n",
      "=================================================================\n",
      "Total params: 7,535\n",
      "Trainable params: 7,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 0.0682 - acc: 0.9718 - val_loss: 2.4879 - val_acc: 0.8429\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0624 - acc: 0.9742 - val_loss: 2.4842 - val_acc: 0.8452\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 0.0654 - acc: 0.9744 - val_loss: 2.4827 - val_acc: 0.8455\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.1222 - acc: 0.9708 - val_loss: 2.4881 - val_acc: 0.8453\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 0.0865 - acc: 0.9726 - val_loss: 2.4857 - val_acc: 0.8453\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0628 - acc: 0.9738 - val_loss: 2.4872 - val_acc: 0.8453\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.0719 - acc: 0.9734 - val_loss: 2.4851 - val_acc: 0.8454\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.0651 - acc: 0.9740 - val_loss: 2.4819 - val_acc: 0.8457\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.0620 - acc: 0.9740 - val_loss: 2.4823 - val_acc: 0.8457\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.0619 - acc: 0.9742 - val_loss: 2.4834 - val_acc: 0.8457\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.0697 - acc: 0.9739 - val_loss: 2.4864 - val_acc: 0.8454\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.0756 - acc: 0.9740 - val_loss: 2.4909 - val_acc: 0.8451\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.1212 - acc: 0.9713 - val_loss: 2.4862 - val_acc: 0.8455\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 58s 45us/step - loss: 0.3202 - acc: 0.9593 - val_loss: 2.4901 - val_acc: 0.8452\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.3193 - acc: 0.9594 - val_loss: 2.4824 - val_acc: 0.8456\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.3539 - acc: 0.9572 - val_loss: 2.4852 - val_acc: 0.8456\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 0.3289 - acc: 0.9587 - val_loss: 2.4859 - val_acc: 0.8455\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 58s 45us/step - loss: 0.3285 - acc: 0.9587 - val_loss: 2.4873 - val_acc: 0.8453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.3202 - acc: 0.9593 - val_loss: 2.4844 - val_acc: 0.8455\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 58s 45us/step - loss: 0.3375 - acc: 0.9586 - val_loss: 2.4838 - val_acc: 0.8457\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.3205 - acc: 0.9600 - val_loss: 2.4987 - val_acc: 0.8445\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.3217 - acc: 0.9594 - val_loss: 2.4854 - val_acc: 0.8455\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 0.3234 - acc: 0.9595 - val_loss: 2.5018 - val_acc: 0.8445\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.3197 - acc: 0.9597 - val_loss: 2.4839 - val_acc: 0.8456\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 0.3211 - acc: 0.9593 - val_loss: 2.4852 - val_acc: 0.8454\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.3200 - acc: 0.9596 - val_loss: 2.4965 - val_acc: 0.8448\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3264 - acc: 0.9595 - val_loss: 2.4828 - val_acc: 0.8457\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.3328 - acc: 0.9590 - val_loss: 2.5032 - val_acc: 0.8444\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3387 - acc: 0.9582 - val_loss: 2.4836 - val_acc: 0.8455\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.6427 - acc: 0.9457 - val_loss: 2.4820 - val_acc: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 3/40 [4:10:28<52:45:27, 5133.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                1820      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 14,945\n",
      "Trainable params: 14,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "=================================================================\n",
      "Total params: 7,445\n",
      "Trainable params: 7,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 6.1203e-04 - acc: 0.3875 - val_loss: 1.5420e-04 - val_acc: 0.3147\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 2.4557e-05 - acc: 0.3485 - val_loss: 1.3877e-04 - val_acc: 0.3046\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.8871e-05 - acc: 0.3049 - val_loss: 1.5596e-04 - val_acc: 0.2626\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.6861e-05 - acc: 0.2989 - val_loss: 1.5413e-04 - val_acc: 0.2711\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.5410e-05 - acc: 0.2603 - val_loss: 1.5056e-04 - val_acc: 0.2669\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.4130e-05 - acc: 0.2591 - val_loss: 1.5111e-04 - val_acc: 0.2919\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 62s 47us/step - loss: 1.3707e-05 - acc: 0.2656 - val_loss: 1.4892e-04 - val_acc: 0.2638\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.3242e-05 - acc: 0.2780 - val_loss: 1.4563e-04 - val_acc: 0.3447\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.3098e-05 - acc: 0.3237 - val_loss: 1.5137e-04 - val_acc: 0.5491\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2540e-05 - acc: 0.2637 - val_loss: 1.4513e-04 - val_acc: 0.3040\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.2135e-05 - acc: 0.2421 - val_loss: 1.4744e-04 - val_acc: 0.3790\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2043e-05 - acc: 0.2187 - val_loss: 1.5434e-04 - val_acc: 0.3211\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.1826e-05 - acc: 0.2308 - val_loss: 1.4324e-04 - val_acc: 0.2555\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2011e-05 - acc: 0.3197 - val_loss: 1.4387e-04 - val_acc: 0.2651\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2367e-05 - acc: 0.4211 - val_loss: 1.4497e-04 - val_acc: 0.2557\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 63s 48us/step - loss: 1.1916e-05 - acc: 0.4082 - val_loss: 1.2054e-04 - val_acc: 0.4901\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.1322e-05 - acc: 0.2807 - val_loss: 1.4157e-04 - val_acc: 0.2582\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 63s 49us/step - loss: 1.1293e-05 - acc: 0.2919 - val_loss: 1.0763e-04 - val_acc: 0.2770\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.1269e-05 - acc: 0.3032 - val_loss: 1.0695e-04 - val_acc: 0.2917\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 70s 54us/step - loss: 1.0837e-05 - acc: 0.2510 - val_loss: 1.1123e-04 - val_acc: 0.5939\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 7,835\n",
      "Trainable params: 7,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0689 - acc: 0.9705 - val_loss: 2.4869 - val_acc: 0.8443\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0628 - acc: 0.9729 - val_loss: 2.4861 - val_acc: 0.8449\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0612 - acc: 0.9735 - val_loss: 2.4830 - val_acc: 0.8454\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0608 - acc: 0.9739 - val_loss: 2.4869 - val_acc: 0.8442\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 63s 48us/step - loss: 0.0622 - acc: 0.9739 - val_loss: 2.4857 - val_acc: 0.8453\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0659 - acc: 0.9741 - val_loss: 2.4865 - val_acc: 0.8451\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 63s 48us/step - loss: 0.0657 - acc: 0.9742 - val_loss: 2.4875 - val_acc: 0.8450\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0642 - acc: 0.9743 - val_loss: 2.4886 - val_acc: 0.8452\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0856 - acc: 0.9731 - val_loss: 2.4874 - val_acc: 0.8453\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0619 - acc: 0.9748 - val_loss: 2.4900 - val_acc: 0.8451\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.2747 - acc: 0.9615 - val_loss: 2.4863 - val_acc: 0.8453\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 62s 47us/step - loss: 0.3073 - acc: 0.9593 - val_loss: 2.4861 - val_acc: 0.8454\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.3019 - acc: 0.9597 - val_loss: 2.4864 - val_acc: 0.8452\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.4975 - acc: 0.9475 - val_loss: 2.4860 - val_acc: 0.8453\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.3162 - acc: 0.9587 - val_loss: 2.4852 - val_acc: 0.8455\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3249 - acc: 0.9582 - val_loss: 2.4887 - val_acc: 0.8451\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.3046 - acc: 0.9594 - val_loss: 2.4896 - val_acc: 0.8453\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3038 - acc: 0.9596 - val_loss: 2.4850 - val_acc: 0.8455\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.3102 - acc: 0.9593 - val_loss: 2.4894 - val_acc: 0.8451\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3033 - acc: 0.9596 - val_loss: 2.4870 - val_acc: 0.8453\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.3726 - acc: 0.9554 - val_loss: 2.4861 - val_acc: 0.8456\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3073 - acc: 0.9593 - val_loss: 2.4864 - val_acc: 0.8454\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3244 - acc: 0.9583 - val_loss: 2.4855 - val_acc: 0.8454\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3095 - acc: 0.9591 - val_loss: 2.4877 - val_acc: 0.8454\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3802 - acc: 0.9548 - val_loss: 2.4884 - val_acc: 0.8452\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.3036 - acc: 0.9594 - val_loss: 2.4882 - val_acc: 0.8454\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.4713 - acc: 0.9491 - val_loss: 2.4956 - val_acc: 0.8447\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.5942 - acc: 0.9416 - val_loss: 2.4866 - val_acc: 0.8455\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.3285 - acc: 0.9579 - val_loss: 2.4880 - val_acc: 0.8452\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.3515 - acc: 0.9565 - val_loss: 2.4881 - val_acc: 0.8453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 4/40 [5:02:08<45:13:47, 4523.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                1860      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4880      \n",
      "=================================================================\n",
      "Total params: 13,430\n",
      "Trainable params: 13,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "=================================================================\n",
      "Total params: 6,690\n",
      "Trainable params: 6,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 119s 91us/step - loss: 3.8593e-04 - acc: 0.2504 - val_loss: 1.2768e-04 - val_acc: 0.3122\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.7758e-05 - acc: 0.2582 - val_loss: 1.1122e-04 - val_acc: 0.3342\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.2707e-05 - acc: 0.2729 - val_loss: 1.0049e-04 - val_acc: 0.4986\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.0756e-05 - acc: 0.2710 - val_loss: 1.2307e-04 - val_acc: 0.2783\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 9.7172e-06 - acc: 0.2694 - val_loss: 9.6650e-05 - val_acc: 0.3252\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 119s 91us/step - loss: 8.9209e-06 - acc: 0.2553 - val_loss: 9.9156e-05 - val_acc: 0.3113\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.0372e-06 - acc: 0.3236 - val_loss: 9.0443e-05 - val_acc: 0.3421\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 7.7878e-06 - acc: 0.3127 - val_loss: 9.1716e-05 - val_acc: 0.3061\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 7.2688e-06 - acc: 0.3154 - val_loss: 8.1339e-05 - val_acc: 0.3804\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 6.6683e-06 - acc: 0.3066 - val_loss: 8.1799e-05 - val_acc: 0.3517\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 6.6700e-06 - acc: 0.3618 - val_loss: 9.6396e-05 - val_acc: 0.4249\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 6.2106e-06 - acc: 0.3613 - val_loss: 8.7844e-05 - val_acc: 0.4672\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 6.5813e-06 - acc: 0.4373 - val_loss: 8.4261e-05 - val_acc: 0.8370\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 6.0285e-06 - acc: 0.5358 - val_loss: 8.4484e-05 - val_acc: 0.4982\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 6.2305e-06 - acc: 0.5546 - val_loss: 8.1551e-05 - val_acc: 0.4611\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.6964e-06 - acc: 0.4228 - val_loss: 8.6673e-05 - val_acc: 0.4640\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 5.8601e-06 - acc: 0.4341 - val_loss: 1.0387e-04 - val_acc: 0.6520\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 6.0597e-06 - acc: 0.4856 - val_loss: 1.0711e-04 - val_acc: 0.5284\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 5.3297e-06 - acc: 0.4519 - val_loss: 8.2048e-05 - val_acc: 0.4345\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 5.6502e-06 - acc: 0.5892 - val_loss: 8.8563e-05 - val_acc: 0.7478\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                465       \n",
      "=================================================================\n",
      "Total params: 7,155\n",
      "Trainable params: 7,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0600 - acc: 0.9714 - val_loss: 2.4573 - val_acc: 0.8459\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0878 - acc: 0.9715 - val_loss: 2.4491 - val_acc: 0.8477\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0624 - acc: 0.9732 - val_loss: 2.4503 - val_acc: 0.8475\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.1006 - acc: 0.9709 - val_loss: 2.4625 - val_acc: 0.8466\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.1150 - acc: 0.9702 - val_loss: 2.4512 - val_acc: 0.8475\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0586 - acc: 0.9738 - val_loss: 2.4497 - val_acc: 0.8476\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0705 - acc: 0.9730 - val_loss: 2.4701 - val_acc: 0.8449\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0585 - acc: 0.9737 - val_loss: 2.4681 - val_acc: 0.8463\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0926 - acc: 0.9716 - val_loss: 2.4533 - val_acc: 0.8473\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0984 - acc: 0.9713 - val_loss: 2.4688 - val_acc: 0.8462\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0658 - acc: 0.9733 - val_loss: 2.4519 - val_acc: 0.8475\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.4344 - acc: 0.9505 - val_loss: 2.4575 - val_acc: 0.8472\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0758 - acc: 0.9727 - val_loss: 2.4547 - val_acc: 0.8474\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0782 - acc: 0.9726 - val_loss: 2.4593 - val_acc: 0.8470\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.1274 - acc: 0.9697 - val_loss: 2.4569 - val_acc: 0.8471\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.1108 - acc: 0.9708 - val_loss: 2.4981 - val_acc: 0.8448\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.2317 - acc: 0.9635 - val_loss: 2.5049 - val_acc: 0.8441\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.2029 - acc: 0.9648 - val_loss: 2.5734 - val_acc: 0.8399\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.5109 - acc: 0.9461 - val_loss: 2.5289 - val_acc: 0.8427\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.3083 - acc: 0.9587 - val_loss: 2.4997 - val_acc: 0.8446\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.6404 - acc: 0.9452 - val_loss: 2.5710 - val_acc: 0.8404\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.3299 - acc: 0.9579 - val_loss: 2.5764 - val_acc: 0.8399\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.5814 - acc: 0.9480 - val_loss: 2.5703 - val_acc: 0.8404\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.1546 - acc: 0.9681 - val_loss: 2.5909 - val_acc: 0.8389\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.3969 - acc: 0.9529 - val_loss: 2.5420 - val_acc: 0.8419\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.1176 - acc: 0.9704 - val_loss: 3.1363 - val_acc: 0.8051\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.1989 - acc: 0.9654 - val_loss: 2.5742 - val_acc: 0.8401\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.1400 - acc: 0.9686 - val_loss: 2.7763 - val_acc: 0.8275\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.2194 - acc: 0.9643 - val_loss: 2.5908 - val_acc: 0.8390\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.2136 - acc: 0.9647 - val_loss: 2.5216 - val_acc: 0.8434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▎        | 5/40 [6:41:38<48:11:37, 4957.08s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4080      \n",
      "=================================================================\n",
      "Total params: 11,210\n",
      "Trainable params: 11,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1530      \n",
      "=================================================================\n",
      "Total params: 5,580\n",
      "Trainable params: 5,580\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0036 - acc: 0.2785 - val_loss: 0.0010 - val_acc: 0.2833\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 4.0461e-04 - acc: 0.3303 - val_loss: 5.2011e-04 - val_acc: 0.3923\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.4312e-04 - acc: 0.4066 - val_loss: 5.0779e-04 - val_acc: 0.3996\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.3330e-04 - acc: 0.4060 - val_loss: 4.9823e-04 - val_acc: 0.4946\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.2575e-04 - acc: 0.4138 - val_loss: 4.9179e-04 - val_acc: 0.4167\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 19s 15us/step - loss: 1.2243e-04 - acc: 0.3950 - val_loss: 4.6825e-04 - val_acc: 0.3183\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.1909e-04 - acc: 0.2780 - val_loss: 1.6354e-04 - val_acc: 0.3542\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 2.4758e-05 - acc: 0.2997 - val_loss: 1.4509e-04 - val_acc: 0.2755\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 2.0110e-05 - acc: 0.2903 - val_loss: 1.4283e-04 - val_acc: 0.3010\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.9214e-05 - acc: 0.2917 - val_loss: 1.4007e-04 - val_acc: 0.3452\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.8511e-05 - acc: 0.3043 - val_loss: 1.4055e-04 - val_acc: 0.2952\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.7821e-05 - acc: 0.2931 - val_loss: 1.4134e-04 - val_acc: 0.3031\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.7304e-05 - acc: 0.2895 - val_loss: 1.3794e-04 - val_acc: 0.3276\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.6934e-05 - acc: 0.3032 - val_loss: 1.4345e-04 - val_acc: 0.3061\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.6954e-05 - acc: 0.2897 - val_loss: 1.4459e-04 - val_acc: 0.3032\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.6240e-05 - acc: 0.2967 - val_loss: 1.4590e-04 - val_acc: 0.3412\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.6027e-05 - acc: 0.3018 - val_loss: 1.4631e-04 - val_acc: 0.3113\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.5579e-05 - acc: 0.3072 - val_loss: 1.4613e-04 - val_acc: 0.3313\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 19s 15us/step - loss: 1.5414e-05 - acc: 0.3078 - val_loss: 1.4981e-04 - val_acc: 0.3510\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.5237e-05 - acc: 0.3058 - val_loss: 1.4592e-04 - val_acc: 0.3049\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1530      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                465       \n",
      "=================================================================\n",
      "Total params: 6,045\n",
      "Trainable params: 6,045\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.1506 - acc: 0.9465 - val_loss: 2.4513 - val_acc: 0.8462\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0497 - acc: 0.9739 - val_loss: 2.4472 - val_acc: 0.8472\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0474 - acc: 0.9746 - val_loss: 2.4499 - val_acc: 0.8463\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0466 - acc: 0.9751 - val_loss: 2.4483 - val_acc: 0.8473\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0462 - acc: 0.9751 - val_loss: 2.4483 - val_acc: 0.8475\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0458 - acc: 0.9754 - val_loss: 2.4493 - val_acc: 0.8471\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0456 - acc: 0.9755 - val_loss: 2.4478 - val_acc: 0.8475\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0454 - acc: 0.9759 - val_loss: 2.4478 - val_acc: 0.8476\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0453 - acc: 0.9759 - val_loss: 2.4477 - val_acc: 0.8476\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0451 - acc: 0.9760 - val_loss: 2.4486 - val_acc: 0.8475\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0449 - acc: 0.9762 - val_loss: 2.4484 - val_acc: 0.8476\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0448 - acc: 0.9763 - val_loss: 2.4478 - val_acc: 0.8476\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0447 - acc: 0.9763 - val_loss: 2.4482 - val_acc: 0.8475\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0446 - acc: 0.9764 - val_loss: 2.4487 - val_acc: 0.8475\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0445 - acc: 0.9764 - val_loss: 2.4475 - val_acc: 0.8478\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0445 - acc: 0.9765 - val_loss: 2.4492 - val_acc: 0.8477\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0444 - acc: 0.9765 - val_loss: 2.4477 - val_acc: 0.8478\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0444 - acc: 0.9765 - val_loss: 2.4479 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0443 - acc: 0.9766 - val_loss: 2.4483 - val_acc: 0.8478\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0442 - acc: 0.9766 - val_loss: 2.4484 - val_acc: 0.8479\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0441 - acc: 0.9767 - val_loss: 2.4486 - val_acc: 0.8475\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0441 - acc: 0.9767 - val_loss: 2.4478 - val_acc: 0.8479\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0441 - acc: 0.9768 - val_loss: 2.4489 - val_acc: 0.8479\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0440 - acc: 0.9768 - val_loss: 2.4489 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0438 - acc: 0.9768 - val_loss: 2.4496 - val_acc: 0.8476\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0438 - acc: 0.9769 - val_loss: 2.4490 - val_acc: 0.8479\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0438 - acc: 0.9769 - val_loss: 2.4494 - val_acc: 0.8478\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0437 - acc: 0.9770 - val_loss: 2.4492 - val_acc: 0.8478\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0436 - acc: 0.9770 - val_loss: 2.4492 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0436 - acc: 0.9771 - val_loss: 2.4483 - val_acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 15%|█▌        | 6/40 [6:56:39<35:19:27, 3740.21s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4080      \n",
      "=================================================================\n",
      "Total params: 10,200\n",
      "Trainable params: 10,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "=================================================================\n",
      "Total params: 5,070\n",
      "Trainable params: 5,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 5.1626e-04 - acc: 0.2583 - val_loss: 1.4844e-04 - val_acc: 0.2692\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 2.7089e-05 - acc: 0.2110 - val_loss: 1.3483e-04 - val_acc: 0.2564\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 2.1028e-05 - acc: 0.2183 - val_loss: 1.3091e-04 - val_acc: 0.2598\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 1.8578e-05 - acc: 0.2518 - val_loss: 1.4093e-04 - val_acc: 0.3091\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 1.6947e-05 - acc: 0.2632 - val_loss: 1.2555e-04 - val_acc: 0.2570\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 1.6146e-05 - acc: 0.2948 - val_loss: 1.2323e-04 - val_acc: 0.3044\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 1.5667e-05 - acc: 0.2872 - val_loss: 1.1791e-04 - val_acc: 0.3213\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 1.4736e-05 - acc: 0.3117 - val_loss: 1.2751e-04 - val_acc: 0.3569\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.4699e-05 - acc: 0.3744 - val_loss: 1.2080e-04 - val_acc: 0.4294\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.4332e-05 - acc: 0.4138 - val_loss: 1.2992e-04 - val_acc: 0.3664\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3871e-05 - acc: 0.4334 - val_loss: 1.1220e-04 - val_acc: 0.5775\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3737e-05 - acc: 0.4642 - val_loss: 1.3622e-04 - val_acc: 0.4789\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3755e-05 - acc: 0.4626 - val_loss: 1.3293e-04 - val_acc: 0.5346\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3487e-05 - acc: 0.5363 - val_loss: 1.2676e-04 - val_acc: 0.3650\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3356e-05 - acc: 0.4630 - val_loss: 1.3067e-04 - val_acc: 0.3102\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3378e-05 - acc: 0.4628 - val_loss: 1.3017e-04 - val_acc: 0.4161\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3201e-05 - acc: 0.5026 - val_loss: 1.2856e-04 - val_acc: 0.3282\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.2922e-05 - acc: 0.4774 - val_loss: 1.3557e-04 - val_acc: 0.3763\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 1.3022e-05 - acc: 0.5212 - val_loss: 1.3974e-04 - val_acc: 0.4200\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3042e-05 - acc: 0.5981 - val_loss: 1.3068e-04 - val_acc: 0.6297\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 5,385\n",
      "Trainable params: 5,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 7.4900 - acc: 0.5293 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 124s 96us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 126s 97us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 7/40 [8:37:14<40:35:47, 4428.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                1820      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 14,945\n",
      "Trainable params: 14,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "=================================================================\n",
      "Total params: 7,445\n",
      "Trainable params: 7,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 3.6787e-04 - acc: 0.3087 - val_loss: 1.2214e-04 - val_acc: 0.2991\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.4900e-05 - acc: 0.2625 - val_loss: 1.1389e-04 - val_acc: 0.2963\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.0731e-05 - acc: 0.2726 - val_loss: 1.0736e-04 - val_acc: 0.3297\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 9.5062e-06 - acc: 0.3708 - val_loss: 1.3024e-04 - val_acc: 0.3829\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 8.5432e-06 - acc: 0.3647 - val_loss: 1.2985e-04 - val_acc: 0.3834\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 7.4942e-06 - acc: 0.4234 - val_loss: 1.3040e-04 - val_acc: 0.3281\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 6.9891e-06 - acc: 0.4312 - val_loss: 1.0682e-04 - val_acc: 0.4399\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 6.8472e-06 - acc: 0.4555 - val_loss: 1.0784e-04 - val_acc: 0.6579\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 6.1745e-06 - acc: 0.4084 - val_loss: 1.2440e-04 - val_acc: 0.3595\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 6.0478e-06 - acc: 0.3801 - val_loss: 1.2574e-04 - val_acc: 0.3660\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 6.2551e-06 - acc: 0.3806 - val_loss: 1.2162e-04 - val_acc: 0.4274\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.8247e-06 - acc: 0.4340 - val_loss: 1.2815e-04 - val_acc: 0.6206\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.7394e-06 - acc: 0.4928 - val_loss: 1.1595e-04 - val_acc: 0.3744\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.2514e-06 - acc: 0.4885 - val_loss: 1.2684e-04 - val_acc: 0.4465\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.0827e-06 - acc: 0.4764 - val_loss: 1.3113e-04 - val_acc: 0.4325\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.0707e-06 - acc: 0.5257 - val_loss: 1.0690e-04 - val_acc: 0.4699\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 119s 91us/step - loss: 4.8858e-06 - acc: 0.5332 - val_loss: 9.9408e-05 - val_acc: 0.4777\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 4.9082e-06 - acc: 0.5134 - val_loss: 1.2433e-04 - val_acc: 0.6821\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.0906e-06 - acc: 0.5464 - val_loss: 1.3314e-04 - val_acc: 0.7231\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 4.8056e-06 - acc: 0.5825 - val_loss: 1.2598e-04 - val_acc: 0.4465\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 7,835\n",
      "Trainable params: 7,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.1710 - acc: 0.9418 - val_loss: 2.4541 - val_acc: 0.8461\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0499 - acc: 0.9746 - val_loss: 2.4495 - val_acc: 0.8472\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0471 - acc: 0.9754 - val_loss: 2.4491 - val_acc: 0.8473\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0460 - acc: 0.9758 - val_loss: 2.4485 - val_acc: 0.8472\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0452 - acc: 0.9761 - val_loss: 2.4488 - val_acc: 0.8471\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0449 - acc: 0.9762 - val_loss: 2.4484 - val_acc: 0.8472\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0446 - acc: 0.9764 - val_loss: 2.4474 - val_acc: 0.8474\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0444 - acc: 0.9764 - val_loss: 2.4471 - val_acc: 0.8474\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0443 - acc: 0.9764 - val_loss: 2.4479 - val_acc: 0.8473\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0441 - acc: 0.9765 - val_loss: 2.4469 - val_acc: 0.8475\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0440 - acc: 0.9765 - val_loss: 2.4465 - val_acc: 0.8475\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0439 - acc: 0.9766 - val_loss: 2.4474 - val_acc: 0.8474\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0438 - acc: 0.9767 - val_loss: 2.4473 - val_acc: 0.8475\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0437 - acc: 0.9767 - val_loss: 2.4474 - val_acc: 0.8475\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0437 - acc: 0.9766 - val_loss: 2.4471 - val_acc: 0.8475\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0436 - acc: 0.9767 - val_loss: 2.4474 - val_acc: 0.8473\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0436 - acc: 0.9767 - val_loss: 2.4468 - val_acc: 0.8475\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0435 - acc: 0.9767 - val_loss: 2.4463 - val_acc: 0.8477\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 116s 89us/step - loss: 0.0435 - acc: 0.9768 - val_loss: 2.4469 - val_acc: 0.8476\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 116s 89us/step - loss: 0.0434 - acc: 0.9768 - val_loss: 2.4468 - val_acc: 0.8477\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 115s 89us/step - loss: 0.0434 - acc: 0.9768 - val_loss: 2.4464 - val_acc: 0.8477\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 115s 89us/step - loss: 0.0434 - acc: 0.9768 - val_loss: 2.4466 - val_acc: 0.8477\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 115s 89us/step - loss: 0.0433 - acc: 0.9769 - val_loss: 2.4468 - val_acc: 0.8477\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0433 - acc: 0.9768 - val_loss: 2.4466 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0433 - acc: 0.9769 - val_loss: 2.4472 - val_acc: 0.8476\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0432 - acc: 0.9769 - val_loss: 2.4468 - val_acc: 0.8478\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0432 - acc: 0.9769 - val_loss: 2.4473 - val_acc: 0.8477\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0432 - acc: 0.9769 - val_loss: 2.4475 - val_acc: 0.8476\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0431 - acc: 0.9769 - val_loss: 2.4472 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 115s 89us/step - loss: 0.0431 - acc: 0.9770 - val_loss: 2.4470 - val_acc: 0.8478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 8/40 [10:15:48<43:19:43, 4874.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                2160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4880      \n",
      "=================================================================\n",
      "Total params: 14,035\n",
      "Trainable params: 14,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "=================================================================\n",
      "Total params: 6,995\n",
      "Trainable params: 6,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0027 - acc: 0.3247 - val_loss: 4.8152e-04 - val_acc: 0.3045\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 1.9774e-04 - acc: 0.2660 - val_loss: 4.2913e-04 - val_acc: 0.2995\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 1.1326e-04 - acc: 0.2741 - val_loss: 1.5590e-04 - val_acc: 0.2741\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 4.5988e-05 - acc: 0.2843 - val_loss: 1.5428e-04 - val_acc: 0.3326\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 4.3365e-05 - acc: 0.2794 - val_loss: 1.5039e-04 - val_acc: 0.2827\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 4.1146e-05 - acc: 0.2941 - val_loss: 1.5579e-04 - val_acc: 0.2912\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 3.8898e-05 - acc: 0.2986 - val_loss: 1.5177e-04 - val_acc: 0.2867\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 3.7340e-05 - acc: 0.2846 - val_loss: 1.4574e-04 - val_acc: 0.2537\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 3.6522e-05 - acc: 0.2961 - val_loss: 1.4184e-04 - val_acc: 0.3320\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 3.5782e-05 - acc: 0.2993 - val_loss: 1.4459e-04 - val_acc: 0.3375\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 2.6247e-05 - acc: 0.2736 - val_loss: 1.3086e-04 - val_acc: 0.3420\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 1.0198e-05 - acc: 0.2887 - val_loss: 1.3163e-04 - val_acc: 0.3600\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 9.8326e-06 - acc: 0.3045 - val_loss: 1.2226e-04 - val_acc: 0.3393\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 9.8018e-06 - acc: 0.2852 - val_loss: 1.2650e-04 - val_acc: 0.3397\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 9.3217e-06 - acc: 0.2873 - val_loss: 1.2330e-04 - val_acc: 0.3448\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 9.1379e-06 - acc: 0.2932 - val_loss: 1.2010e-04 - val_acc: 0.3669\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 8.9246e-06 - acc: 0.2940 - val_loss: 1.1701e-04 - val_acc: 0.3743\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 8.7748e-06 - acc: 0.2977 - val_loss: 1.1648e-04 - val_acc: 0.3551\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 8.6267e-06 - acc: 0.2961 - val_loss: 1.1699e-04 - val_acc: 0.3600\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 8.4691e-06 - acc: 0.2927 - val_loss: 1.1440e-04 - val_acc: 0.3531\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                540       \n",
      "=================================================================\n",
      "Total params: 7,535\n",
      "Trainable params: 7,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.1339 - acc: 0.9522 - val_loss: 2.4479 - val_acc: 0.8444\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0485 - acc: 0.9744 - val_loss: 2.4477 - val_acc: 0.8470\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0466 - acc: 0.9753 - val_loss: 2.4482 - val_acc: 0.8474\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0457 - acc: 0.9757 - val_loss: 2.4475 - val_acc: 0.8476\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0451 - acc: 0.9759 - val_loss: 2.4477 - val_acc: 0.8476\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0446 - acc: 0.9761 - val_loss: 2.4476 - val_acc: 0.8475\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0443 - acc: 0.9764 - val_loss: 2.4480 - val_acc: 0.8468\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0441 - acc: 0.9765 - val_loss: 2.4480 - val_acc: 0.8477\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0439 - acc: 0.9766 - val_loss: 2.4473 - val_acc: 0.8478\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0438 - acc: 0.9767 - val_loss: 2.4466 - val_acc: 0.8480\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0437 - acc: 0.9767 - val_loss: 2.4482 - val_acc: 0.8470\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0435 - acc: 0.9768 - val_loss: 2.4467 - val_acc: 0.8478\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0435 - acc: 0.9769 - val_loss: 2.4471 - val_acc: 0.8478\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0433 - acc: 0.9769 - val_loss: 2.4472 - val_acc: 0.8478\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0433 - acc: 0.9770 - val_loss: 2.4474 - val_acc: 0.8477\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0431 - acc: 0.9771 - val_loss: 2.4473 - val_acc: 0.8477\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0430 - acc: 0.9773 - val_loss: 2.4474 - val_acc: 0.8478\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0429 - acc: 0.9773 - val_loss: 2.4468 - val_acc: 0.8480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0427 - acc: 0.9775 - val_loss: 2.4470 - val_acc: 0.8480\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0427 - acc: 0.9776 - val_loss: 2.4471 - val_acc: 0.8478\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0425 - acc: 0.9777 - val_loss: 2.4468 - val_acc: 0.8478\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0424 - acc: 0.9777 - val_loss: 2.4468 - val_acc: 0.8479\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0424 - acc: 0.9777 - val_loss: 2.4467 - val_acc: 0.8479\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0423 - acc: 0.9777 - val_loss: 2.4472 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0423 - acc: 0.9778 - val_loss: 2.4476 - val_acc: 0.8477\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0422 - acc: 0.9777 - val_loss: 2.4471 - val_acc: 0.8478\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0422 - acc: 0.9778 - val_loss: 2.4469 - val_acc: 0.8480\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0421 - acc: 0.9778 - val_loss: 2.4473 - val_acc: 0.8479\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0420 - acc: 0.9778 - val_loss: 2.4470 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0420 - acc: 0.9778 - val_loss: 2.4486 - val_acc: 0.8473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▎       | 9/40 [10:30:14<31:37:03, 3671.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                1820      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 14,945\n",
      "Trainable params: 14,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "=================================================================\n",
      "Total params: 7,445\n",
      "Trainable params: 7,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 19s 15us/step - loss: 0.0029 - acc: 0.2686 - val_loss: 2.0657e-04 - val_acc: 0.2986\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 5.0401e-05 - acc: 0.2709 - val_loss: 1.6150e-04 - val_acc: 0.2722\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 3.1170e-05 - acc: 0.2794 - val_loss: 1.5332e-04 - val_acc: 0.3394\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 2.3256e-05 - acc: 0.3674 - val_loss: 1.4792e-04 - val_acc: 0.2568\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 2.0258e-05 - acc: 0.3884 - val_loss: 1.4055e-04 - val_acc: 0.3671\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.8499e-05 - acc: 0.2893 - val_loss: 1.4264e-04 - val_acc: 0.3098\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.6949e-05 - acc: 0.2732 - val_loss: 1.3157e-04 - val_acc: 0.3072\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.5996e-05 - acc: 0.2459 - val_loss: 1.2728e-04 - val_acc: 0.2686\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.5267e-05 - acc: 0.2502 - val_loss: 1.2295e-04 - val_acc: 0.2619\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.4679e-05 - acc: 0.2135 - val_loss: 1.2156e-04 - val_acc: 0.2707\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.4206e-05 - acc: 0.2107 - val_loss: 1.1910e-04 - val_acc: 0.2670\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.4000e-05 - acc: 0.2322 - val_loss: 1.1709e-04 - val_acc: 0.2344\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.3474e-05 - acc: 0.2295 - val_loss: 1.1639e-04 - val_acc: 0.2638\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.3054e-05 - acc: 0.2402 - val_loss: 1.1459e-04 - val_acc: 0.2804\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.3190e-05 - acc: 0.2635 - val_loss: 1.1562e-04 - val_acc: 0.2931\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.2298e-05 - acc: 0.2453 - val_loss: 1.1285e-04 - val_acc: 0.2779\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.2001e-05 - acc: 0.2339 - val_loss: 1.1179e-04 - val_acc: 0.2736\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.1825e-05 - acc: 0.2110 - val_loss: 1.0991e-04 - val_acc: 0.2794\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.1583e-05 - acc: 0.2059 - val_loss: 1.1188e-04 - val_acc: 0.2833\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.1438e-05 - acc: 0.2064 - val_loss: 1.1765e-04 - val_acc: 0.2788\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1775      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 7,835\n",
      "Trainable params: 7,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 3.1952 - acc: 0.7759 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 17s 14us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 25%|██▌       | 10/40 [10:45:05<23:38:45, 2837.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                1860      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4880      \n",
      "=================================================================\n",
      "Total params: 13,430\n",
      "Trainable params: 13,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "=================================================================\n",
      "Total params: 6,690\n",
      "Trainable params: 6,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 9.1491e-04 - acc: 0.3316 - val_loss: 1.7777e-04 - val_acc: 0.4050\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 64s 50us/step - loss: 2.2914e-05 - acc: 0.3119 - val_loss: 1.4947e-04 - val_acc: 0.3585\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.6438e-05 - acc: 0.2997 - val_loss: 1.4161e-04 - val_acc: 0.3259\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2091e-05 - acc: 0.2397 - val_loss: 1.3604e-04 - val_acc: 0.2422\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.0084e-05 - acc: 0.2927 - val_loss: 1.2912e-04 - val_acc: 0.3000\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 8.6807e-06 - acc: 0.2416 - val_loss: 1.1525e-04 - val_acc: 0.2439\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3598e-06 - acc: 0.3341 - val_loss: 1.2150e-04 - val_acc: 0.3269\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 7.6879e-06 - acc: 0.3659 - val_loss: 1.2212e-04 - val_acc: 0.3397\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 7.3231e-06 - acc: 0.3244 - val_loss: 1.0551e-04 - val_acc: 0.2562\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 6.6678e-06 - acc: 0.2424 - val_loss: 1.1795e-04 - val_acc: 0.2470\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 6.0823e-06 - acc: 0.2740 - val_loss: 1.1809e-04 - val_acc: 0.2509\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 6.2211e-06 - acc: 0.3775 - val_loss: 1.1928e-04 - val_acc: 0.2604\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 5.7786e-06 - acc: 0.3196 - val_loss: 1.1472e-04 - val_acc: 0.2532\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 5.6642e-06 - acc: 0.3745 - val_loss: 1.1629e-04 - val_acc: 0.3960\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 5.3598e-06 - acc: 0.4162 - val_loss: 1.1702e-04 - val_acc: 0.2449\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 5.0864e-06 - acc: 0.3553 - val_loss: 1.1673e-04 - val_acc: 0.3639\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 5.0023e-06 - acc: 0.3830 - val_loss: 1.1721e-04 - val_acc: 0.3123\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 5.0125e-06 - acc: 0.3142 - val_loss: 1.1851e-04 - val_acc: 0.3009\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 4.6478e-06 - acc: 0.3162 - val_loss: 1.1730e-04 - val_acc: 0.2822\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 4.5350e-06 - acc: 0.3495 - val_loss: 1.1461e-04 - val_acc: 0.2833\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                465       \n",
      "=================================================================\n",
      "Total params: 7,155\n",
      "Trainable params: 7,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 6.8342 - acc: 0.5672 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.3892 - acc: 0.4795 - val_loss: 7.0692 - val_acc: 0.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 11/40 [11:35:43<23:20:33, 2897.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                2130      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                2170      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 15,650\n",
      "Trainable params: 15,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                2130      \n",
      "=================================================================\n",
      "Total params: 7,800\n",
      "Trainable params: 7,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 4.0848e-04 - acc: 0.2821 - val_loss: 1.4382e-04 - val_acc: 0.2502\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 2.1663e-05 - acc: 0.1943 - val_loss: 1.3912e-04 - val_acc: 0.2443\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.7947e-05 - acc: 0.1889 - val_loss: 1.2989e-04 - val_acc: 0.2539\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.6052e-05 - acc: 0.2273 - val_loss: 1.4687e-04 - val_acc: 0.3124\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.5293e-05 - acc: 0.2310 - val_loss: 1.3574e-04 - val_acc: 0.3187\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.4656e-05 - acc: 0.2728 - val_loss: 1.4100e-04 - val_acc: 0.3603\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.3740e-05 - acc: 0.2800 - val_loss: 1.3968e-04 - val_acc: 0.3375\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.4018e-05 - acc: 0.2395 - val_loss: 1.3220e-04 - val_acc: 0.2742\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.3101e-05 - acc: 0.2213 - val_loss: 1.3663e-04 - val_acc: 0.2665\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.2688e-05 - acc: 0.2196 - val_loss: 1.2795e-04 - val_acc: 0.3937\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.3328e-05 - acc: 0.3024 - val_loss: 1.3223e-04 - val_acc: 0.3076\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.1014e-05 - acc: 0.2482 - val_loss: 1.3130e-04 - val_acc: 0.2733\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 1.1165e-05 - acc: 0.2291 - val_loss: 1.3731e-04 - val_acc: 0.2693\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 9.7833e-06 - acc: 0.2308 - val_loss: 1.1367e-04 - val_acc: 0.2578\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 6.6875e-06 - acc: 0.2208 - val_loss: 1.1019e-04 - val_acc: 0.3746\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 5.1064e-06 - acc: 0.2466 - val_loss: 1.0869e-04 - val_acc: 0.2849\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 4.8204e-06 - acc: 0.2644 - val_loss: 1.1158e-04 - val_acc: 0.2909\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 4.8743e-06 - acc: 0.2565 - val_loss: 1.0662e-04 - val_acc: 0.3082\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 5.1470e-06 - acc: 0.3517 - val_loss: 9.0822e-05 - val_acc: 0.3911\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 4.7202e-06 - acc: 0.3148 - val_loss: 8.7619e-05 - val_acc: 0.4127\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                2130      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                465       \n",
      "=================================================================\n",
      "Total params: 8,265\n",
      "Trainable params: 8,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 7.0264 - acc: 0.5558 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 119s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3891 - acc: 0.4795 - val_loss: 7.0689 - val_acc: 0.5614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 12/40 [13:15:16<29:42:49, 3820.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                1785      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1800      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4080      \n",
      "=================================================================\n",
      "Total params: 11,715\n",
      "Trainable params: 11,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                1785      \n",
      "=================================================================\n",
      "Total params: 5,835\n",
      "Trainable params: 5,835\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0064 - acc: 0.4919 - val_loss: 0.0035 - val_acc: 0.6150\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0023 - acc: 0.5753 - val_loss: 0.0022 - val_acc: 0.5619\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0021 - acc: 0.3421 - val_loss: 0.0022 - val_acc: 0.4534\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0021 - acc: 0.2898 - val_loss: 0.0021 - val_acc: 0.4720\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0019 - acc: 0.4553 - val_loss: 0.0017 - val_acc: 0.5261\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 0.0013 - acc: 0.4758 - val_loss: 0.0013 - val_acc: 0.5325\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 2.8908e-04 - acc: 0.5107 - val_loss: 2.5283e-04 - val_acc: 0.5540\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 8.8446e-05 - acc: 0.5274 - val_loss: 2.3182e-04 - val_acc: 0.5739\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 8.5701e-05 - acc: 0.5050 - val_loss: 2.1889e-04 - val_acc: 0.5466\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 3.7237e-05 - acc: 0.4935 - val_loss: 1.4298e-04 - val_acc: 0.5425\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.8619e-05 - acc: 0.4885 - val_loss: 1.3620e-04 - val_acc: 0.5329\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.7438e-05 - acc: 0.4884 - val_loss: 1.3187e-04 - val_acc: 0.5559\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.6714e-05 - acc: 0.4996 - val_loss: 1.2682e-04 - val_acc: 0.5657\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.5797e-05 - acc: 0.5057 - val_loss: 1.2244e-04 - val_acc: 0.5568\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.4846e-05 - acc: 0.5080 - val_loss: 1.2508e-04 - val_acc: 0.5355\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.4362e-05 - acc: 0.5075 - val_loss: 1.1956e-04 - val_acc: 0.5574\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.4072e-05 - acc: 0.5099 - val_loss: 1.1851e-04 - val_acc: 0.5671\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.3785e-05 - acc: 0.5185 - val_loss: 1.1801e-04 - val_acc: 0.5578\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.3468e-05 - acc: 0.5136 - val_loss: 1.2015e-04 - val_acc: 0.5571\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.3256e-05 - acc: 0.4984 - val_loss: 1.2046e-04 - val_acc: 0.5595\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                1785      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                540       \n",
      "=================================================================\n",
      "Total params: 6,375\n",
      "Trainable params: 6,375\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0630 - acc: 0.9694 - val_loss: 2.4504 - val_acc: 0.8471\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0479 - acc: 0.9740 - val_loss: 2.4440 - val_acc: 0.8470\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0473 - acc: 0.9745 - val_loss: 2.4492 - val_acc: 0.8474\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0501 - acc: 0.9748 - val_loss: 2.4500 - val_acc: 0.8473\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0462 - acc: 0.9753 - val_loss: 2.4503 - val_acc: 0.8473\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0459 - acc: 0.9757 - val_loss: 2.4492 - val_acc: 0.8476\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0483 - acc: 0.9752 - val_loss: 2.4511 - val_acc: 0.8473\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0457 - acc: 0.9755 - val_loss: 2.4537 - val_acc: 0.8472\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0452 - acc: 0.9755 - val_loss: 2.4525 - val_acc: 0.8473\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0469 - acc: 0.9758 - val_loss: 2.4511 - val_acc: 0.8477\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0477 - acc: 0.9758 - val_loss: 2.4517 - val_acc: 0.8476\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0482 - acc: 0.9761 - val_loss: 2.4527 - val_acc: 0.8470\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.1872 - acc: 0.9675 - val_loss: 2.4510 - val_acc: 0.8477\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.9021 - acc: 0.9231 - val_loss: 2.4488 - val_acc: 0.8477\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.2536 - acc: 0.9633 - val_loss: 2.4491 - val_acc: 0.8477\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0448 - acc: 0.9765 - val_loss: 2.4493 - val_acc: 0.8476\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0588 - acc: 0.9754 - val_loss: 2.4480 - val_acc: 0.8480\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0453 - acc: 0.9766 - val_loss: 2.4475 - val_acc: 0.8479\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.2348 - acc: 0.9649 - val_loss: 2.4485 - val_acc: 0.8479\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.6678 - acc: 0.9379 - val_loss: 2.4512 - val_acc: 0.8478\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0473 - acc: 0.9766 - val_loss: 2.4523 - val_acc: 0.8474\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0516 - acc: 0.9759 - val_loss: 2.4563 - val_acc: 0.8470\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0453 - acc: 0.9767 - val_loss: 2.4511 - val_acc: 0.8477\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0462 - acc: 0.9765 - val_loss: 2.4480 - val_acc: 0.8479\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0458 - acc: 0.9765 - val_loss: 2.4507 - val_acc: 0.8473\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0461 - acc: 0.9762 - val_loss: 2.4531 - val_acc: 0.8474\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0948 - acc: 0.9736 - val_loss: 2.4506 - val_acc: 0.8471\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.9735 - acc: 0.9191 - val_loss: 2.4535 - val_acc: 0.8474\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0449 - acc: 0.9770 - val_loss: 2.4516 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.1528 - acc: 0.9703 - val_loss: 2.4524 - val_acc: 0.8476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▎      | 13/40 [13:29:49<22:01:15, 2936.14s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1420      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                1470      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 14,240\n",
      "Trainable params: 14,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1420      \n",
      "=================================================================\n",
      "Total params: 7,090\n",
      "Trainable params: 7,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 8.9641e-04 - acc: 0.2902 - val_loss: 1.5648e-04 - val_acc: 0.2674\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 3.0318e-05 - acc: 0.2734 - val_loss: 1.4755e-04 - val_acc: 0.2787\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 2.2230e-05 - acc: 0.2911 - val_loss: 1.3204e-04 - val_acc: 0.3259\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 1.8436e-05 - acc: 0.2678 - val_loss: 1.2597e-04 - val_acc: 0.2563\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.6652e-05 - acc: 0.2497 - val_loss: 1.2348e-04 - val_acc: 0.2563\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.5668e-05 - acc: 0.2339 - val_loss: 1.2526e-04 - val_acc: 0.2626\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.4652e-05 - acc: 0.2393 - val_loss: 1.1784e-04 - val_acc: 0.2562\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 1.4508e-05 - acc: 0.2721 - val_loss: 1.1508e-04 - val_acc: 0.2721\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.3974e-05 - acc: 0.3031 - val_loss: 1.2307e-04 - val_acc: 0.2952\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.3742e-05 - acc: 0.3508 - val_loss: 1.2729e-04 - val_acc: 0.3464\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.3171e-05 - acc: 0.3443 - val_loss: 1.1942e-04 - val_acc: 0.3098\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.2676e-05 - acc: 0.3251 - val_loss: 1.2270e-04 - val_acc: 0.3033\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.2318e-05 - acc: 0.3252 - val_loss: 1.0913e-04 - val_acc: 0.3273\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 1.2235e-05 - acc: 0.3495 - val_loss: 1.2205e-04 - val_acc: 0.2906\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.2182e-05 - acc: 0.3299 - val_loss: 1.0783e-04 - val_acc: 0.3306\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.2156e-05 - acc: 0.3810 - val_loss: 1.3811e-04 - val_acc: 0.4345\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.1707e-05 - acc: 0.4141 - val_loss: 1.1888e-04 - val_acc: 0.3649\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.1744e-05 - acc: 0.3695 - val_loss: 1.2427e-04 - val_acc: 0.3129\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.1329e-05 - acc: 0.3478 - val_loss: 1.2381e-04 - val_acc: 0.3716\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 1.1459e-05 - acc: 0.3821 - val_loss: 1.1625e-04 - val_acc: 0.3671\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1420      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 7,405\n",
      "Trainable params: 7,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 59s 45us/step - loss: 0.2614 - acc: 0.9176 - val_loss: 2.4904 - val_acc: 0.8408\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 58s 45us/step - loss: 0.0648 - acc: 0.9734 - val_loss: 2.4871 - val_acc: 0.8442\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0585 - acc: 0.9742 - val_loss: 2.4825 - val_acc: 0.8449\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0566 - acc: 0.9747 - val_loss: 2.4820 - val_acc: 0.8451\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0557 - acc: 0.9750 - val_loss: 2.4814 - val_acc: 0.8454\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0551 - acc: 0.9752 - val_loss: 2.4814 - val_acc: 0.8453\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0546 - acc: 0.9754 - val_loss: 2.4812 - val_acc: 0.8454\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0543 - acc: 0.9754 - val_loss: 2.4808 - val_acc: 0.8455\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0541 - acc: 0.9756 - val_loss: 2.4807 - val_acc: 0.8455\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0538 - acc: 0.9757 - val_loss: 2.4808 - val_acc: 0.8455\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0536 - acc: 0.9757 - val_loss: 2.4803 - val_acc: 0.8456\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0535 - acc: 0.9759 - val_loss: 2.4803 - val_acc: 0.8455\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0533 - acc: 0.9759 - val_loss: 2.4802 - val_acc: 0.8456\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0532 - acc: 0.9760 - val_loss: 2.4802 - val_acc: 0.8455\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0531 - acc: 0.9760 - val_loss: 2.4799 - val_acc: 0.8456\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0530 - acc: 0.9761 - val_loss: 2.4798 - val_acc: 0.8456\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0529 - acc: 0.9761 - val_loss: 2.4801 - val_acc: 0.8456\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0528 - acc: 0.9762 - val_loss: 2.4802 - val_acc: 0.8456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0528 - acc: 0.9762 - val_loss: 2.4797 - val_acc: 0.8457\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0528 - acc: 0.9762 - val_loss: 2.4799 - val_acc: 0.8456\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0527 - acc: 0.9762 - val_loss: 2.4800 - val_acc: 0.8456\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0526 - acc: 0.9763 - val_loss: 2.4796 - val_acc: 0.8457\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0526 - acc: 0.9764 - val_loss: 2.4792 - val_acc: 0.8458\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0526 - acc: 0.9763 - val_loss: 2.4798 - val_acc: 0.8457\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 0.0525 - acc: 0.9763 - val_loss: 2.4792 - val_acc: 0.8458\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0525 - acc: 0.9763 - val_loss: 2.4795 - val_acc: 0.8458\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0525 - acc: 0.9764 - val_loss: 2.4791 - val_acc: 0.8458\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 59s 46us/step - loss: 0.0525 - acc: 0.9762 - val_loss: 2.4794 - val_acc: 0.8458\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0524 - acc: 0.9762 - val_loss: 2.4794 - val_acc: 0.8458\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0524 - acc: 0.9762 - val_loss: 2.4793 - val_acc: 0.8458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 14/40 [14:20:09<21:23:13, 2961.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4080      \n",
      "=================================================================\n",
      "Total params: 10,705\n",
      "Trainable params: 10,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "=================================================================\n",
      "Total params: 5,325\n",
      "Trainable params: 5,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 5.8838e-04 - acc: 0.2437 - val_loss: 1.9260e-04 - val_acc: 0.2629\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.9851e-05 - acc: 0.2652 - val_loss: 1.2644e-04 - val_acc: 0.2749\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.4320e-05 - acc: 0.2690 - val_loss: 1.2248e-04 - val_acc: 0.3009\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.2168e-05 - acc: 0.2376 - val_loss: 1.0936e-04 - val_acc: 0.2758\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 119s 91us/step - loss: 1.1075e-05 - acc: 0.2704 - val_loss: 1.2118e-04 - val_acc: 0.3136\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.0152e-05 - acc: 0.2762 - val_loss: 1.0769e-04 - val_acc: 0.5321\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 9.1850e-06 - acc: 0.2996 - val_loss: 1.1039e-04 - val_acc: 0.3264\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 9.0974e-06 - acc: 0.3001 - val_loss: 9.9158e-05 - val_acc: 0.3369\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.6334e-06 - acc: 0.3303 - val_loss: 1.2350e-04 - val_acc: 0.3513\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.3112e-06 - acc: 0.3462 - val_loss: 1.0092e-04 - val_acc: 0.3309\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 8.1299e-06 - acc: 0.3710 - val_loss: 1.2740e-04 - val_acc: 0.3692\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 8.2401e-06 - acc: 0.3564 - val_loss: 9.4282e-05 - val_acc: 0.3203\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 7.8357e-06 - acc: 0.4187 - val_loss: 1.1759e-04 - val_acc: 0.3815\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 7.5562e-06 - acc: 0.4370 - val_loss: 1.0542e-04 - val_acc: 0.4393\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 7.4861e-06 - acc: 0.4254 - val_loss: 1.1500e-04 - val_acc: 0.6251\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 116s 89us/step - loss: 7.2231e-06 - acc: 0.5288 - val_loss: 1.0823e-04 - val_acc: 0.3481\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 7.5564e-06 - acc: 0.4660 - val_loss: 9.8711e-05 - val_acc: 0.4035\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 7.0293e-06 - acc: 0.4331 - val_loss: 1.0127e-04 - val_acc: 0.3384\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 7.2693e-06 - acc: 0.4899 - val_loss: 1.1637e-04 - val_acc: 0.3912\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 7.1922e-06 - acc: 0.5672 - val_loss: 1.0236e-04 - val_acc: 0.4066\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 5,715\n",
      "Trainable params: 5,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.1645 - acc: 0.9445 - val_loss: 2.4556 - val_acc: 0.8455\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0509 - acc: 0.9746 - val_loss: 2.4512 - val_acc: 0.8466\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0473 - acc: 0.9756 - val_loss: 2.4510 - val_acc: 0.8466\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0460 - acc: 0.9760 - val_loss: 2.4507 - val_acc: 0.8469\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0454 - acc: 0.9761 - val_loss: 2.4495 - val_acc: 0.8472\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0450 - acc: 0.9763 - val_loss: 2.4498 - val_acc: 0.8470\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0447 - acc: 0.9764 - val_loss: 2.4485 - val_acc: 0.8473\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0445 - acc: 0.9764 - val_loss: 2.4483 - val_acc: 0.8475\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0444 - acc: 0.9765 - val_loss: 2.4486 - val_acc: 0.8474\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0442 - acc: 0.9766 - val_loss: 2.4494 - val_acc: 0.8473\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0441 - acc: 0.9766 - val_loss: 2.4480 - val_acc: 0.8475\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0440 - acc: 0.9766 - val_loss: 2.4487 - val_acc: 0.8470\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0439 - acc: 0.9767 - val_loss: 2.4476 - val_acc: 0.8476\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0439 - acc: 0.9767 - val_loss: 2.4483 - val_acc: 0.8475\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0438 - acc: 0.9767 - val_loss: 2.4482 - val_acc: 0.8474\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0437 - acc: 0.9767 - val_loss: 2.4473 - val_acc: 0.8476\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0437 - acc: 0.9767 - val_loss: 2.4473 - val_acc: 0.8477\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0437 - acc: 0.9767 - val_loss: 2.4475 - val_acc: 0.8476\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0436 - acc: 0.9767 - val_loss: 2.4471 - val_acc: 0.8478\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0436 - acc: 0.9768 - val_loss: 2.4477 - val_acc: 0.8475\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0436 - acc: 0.9767 - val_loss: 2.4473 - val_acc: 0.8477\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0435 - acc: 0.9768 - val_loss: 2.4468 - val_acc: 0.8478\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0435 - acc: 0.9768 - val_loss: 2.4467 - val_acc: 0.8479\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0435 - acc: 0.9768 - val_loss: 2.4473 - val_acc: 0.8477\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0435 - acc: 0.9769 - val_loss: 2.4472 - val_acc: 0.8477\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0434 - acc: 0.9768 - val_loss: 2.4477 - val_acc: 0.8475\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0434 - acc: 0.9768 - val_loss: 2.4472 - val_acc: 0.8478\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0434 - acc: 0.9768 - val_loss: 2.4475 - val_acc: 0.8475\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0433 - acc: 0.9769 - val_loss: 2.4480 - val_acc: 0.8474\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0433 - acc: 0.9769 - val_loss: 2.4471 - val_acc: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 15/40 [15:59:01<26:45:10, 3852.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1420      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                1470      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 14,240\n",
      "Trainable params: 14,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1420      \n",
      "=================================================================\n",
      "Total params: 7,090\n",
      "Trainable params: 7,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 4.9289e-04 - acc: 0.2713 - val_loss: 1.8303e-04 - val_acc: 0.2661\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 2.5173e-05 - acc: 0.2876 - val_loss: 1.4894e-04 - val_acc: 0.2623\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.9354e-05 - acc: 0.2659 - val_loss: 1.2588e-04 - val_acc: 0.3574\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.6839e-05 - acc: 0.2391 - val_loss: 1.2378e-04 - val_acc: 0.2803\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.6238e-05 - acc: 0.2933 - val_loss: 1.1794e-04 - val_acc: 0.2800\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.5606e-05 - acc: 0.2955 - val_loss: 1.3051e-04 - val_acc: 0.2722\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.5151e-05 - acc: 0.3427 - val_loss: 1.2399e-04 - val_acc: 0.2926\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.4762e-05 - acc: 0.3402 - val_loss: 1.3990e-04 - val_acc: 0.4584\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.4463e-05 - acc: 0.3581 - val_loss: 1.2331e-04 - val_acc: 0.3375\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.3879e-05 - acc: 0.3565 - val_loss: 1.1963e-04 - val_acc: 0.4139\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.3724e-05 - acc: 0.4023 - val_loss: 1.3055e-04 - val_acc: 0.3961\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 117s 91us/step - loss: 1.3508e-05 - acc: 0.3509 - val_loss: 1.3732e-04 - val_acc: 0.3886\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 1.3179e-05 - acc: 0.3651 - val_loss: 1.1882e-04 - val_acc: 0.4200\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.3089e-05 - acc: 0.3782 - val_loss: 1.3055e-04 - val_acc: 0.3306\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.3032e-05 - acc: 0.3501 - val_loss: 1.3209e-04 - val_acc: 0.4714\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.3072e-05 - acc: 0.3733 - val_loss: 1.3204e-04 - val_acc: 0.4582\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 117s 91us/step - loss: 1.2642e-05 - acc: 0.3835 - val_loss: 1.3554e-04 - val_acc: 0.4806\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.2958e-05 - acc: 0.4013 - val_loss: 1.4651e-04 - val_acc: 0.6945\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 1.2499e-05 - acc: 0.4123 - val_loss: 1.3366e-04 - val_acc: 0.6292\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 1.2532e-05 - acc: 0.4822 - val_loss: 1.3302e-04 - val_acc: 0.6200\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                1420      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                315       \n",
      "=================================================================\n",
      "Total params: 7,405\n",
      "Trainable params: 7,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0712 - acc: 0.9703 - val_loss: 2.4861 - val_acc: 0.8452\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0694 - acc: 0.9726 - val_loss: 2.4845 - val_acc: 0.8452\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0777 - acc: 0.9724 - val_loss: 2.4976 - val_acc: 0.8445\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.1128 - acc: 0.9704 - val_loss: 2.4874 - val_acc: 0.8453\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0717 - acc: 0.9729 - val_loss: 2.4901 - val_acc: 0.8450\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.1026 - acc: 0.9712 - val_loss: 2.4913 - val_acc: 0.8448\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.4215 - acc: 0.9513 - val_loss: 2.4875 - val_acc: 0.8451\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.2702 - acc: 0.9612 - val_loss: 2.4963 - val_acc: 0.8447\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0704 - acc: 0.9736 - val_loss: 2.4943 - val_acc: 0.8448\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.1222 - acc: 0.9706 - val_loss: 2.4941 - val_acc: 0.8446\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.3797 - acc: 0.9548 - val_loss: 2.4855 - val_acc: 0.8454\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.3418 - acc: 0.9570 - val_loss: 2.5011 - val_acc: 0.8444\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0803 - acc: 0.9736 - val_loss: 2.5057 - val_acc: 0.8443\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0916 - acc: 0.9732 - val_loss: 2.4998 - val_acc: 0.8444\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.2836 - acc: 0.9613 - val_loss: 2.4843 - val_acc: 0.8457\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0794 - acc: 0.9737 - val_loss: 2.4934 - val_acc: 0.8450\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.1301 - acc: 0.9708 - val_loss: 2.5054 - val_acc: 0.8443\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0967 - acc: 0.9729 - val_loss: 2.4848 - val_acc: 0.8455\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.3968 - acc: 0.9548 - val_loss: 2.5003 - val_acc: 0.8446\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.5696 - acc: 0.9436 - val_loss: 2.4879 - val_acc: 0.8454\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0835 - acc: 0.9738 - val_loss: 2.4845 - val_acc: 0.8455\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.2018 - acc: 0.9667 - val_loss: 2.4845 - val_acc: 0.8457\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.5666 - acc: 0.9442 - val_loss: 2.4893 - val_acc: 0.8454\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0825 - acc: 0.9740 - val_loss: 2.5272 - val_acc: 0.8429\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0976 - acc: 0.9729 - val_loss: 2.4874 - val_acc: 0.8454\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.2077 - acc: 0.9659 - val_loss: 2.5159 - val_acc: 0.8427\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.3219 - acc: 0.9693 - val_loss: 2.4858 - val_acc: 0.8455\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.3780 - acc: 0.9554 - val_loss: 2.5218 - val_acc: 0.8431\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 117s 90us/step - loss: 0.0928 - acc: 0.9731 - val_loss: 2.5006 - val_acc: 0.8447\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 116s 90us/step - loss: 0.0660 - acc: 0.9747 - val_loss: 2.4980 - val_acc: 0.8449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 16/40 [17:37:07<29:44:59, 4462.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                1300      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4080      \n",
      "=================================================================\n",
      "Total params: 10,705\n",
      "Trainable params: 10,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "=================================================================\n",
      "Total params: 5,325\n",
      "Trainable params: 5,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 8.2146e-04 - acc: 0.3386 - val_loss: 1.6342e-04 - val_acc: 0.2677\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 3.0579e-05 - acc: 0.2861 - val_loss: 1.4376e-04 - val_acc: 0.2569\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 2.3564e-05 - acc: 0.2597 - val_loss: 1.3822e-04 - val_acc: 0.2565\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 2.0280e-05 - acc: 0.2456 - val_loss: 1.3341e-04 - val_acc: 0.2571\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.8339e-05 - acc: 0.2495 - val_loss: 1.3101e-04 - val_acc: 0.2527\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.6864e-05 - acc: 0.2268 - val_loss: 1.2806e-04 - val_acc: 0.2657\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.6010e-05 - acc: 0.2374 - val_loss: 1.2438e-04 - val_acc: 0.2651\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.5195e-05 - acc: 0.2360 - val_loss: 1.2750e-04 - val_acc: 0.2785\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.4795e-05 - acc: 0.2413 - val_loss: 1.3287e-04 - val_acc: 0.2750\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.4086e-05 - acc: 0.2370 - val_loss: 1.3486e-04 - val_acc: 0.2689\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.3742e-05 - acc: 0.2296 - val_loss: 1.2938e-04 - val_acc: 0.5560\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.3631e-05 - acc: 0.2634 - val_loss: 1.2510e-04 - val_acc: 0.2834\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.3107e-05 - acc: 0.2629 - val_loss: 1.2542e-04 - val_acc: 0.2818\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2806e-05 - acc: 0.2257 - val_loss: 1.3695e-04 - val_acc: 0.2796\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2835e-05 - acc: 0.2213 - val_loss: 1.1740e-04 - val_acc: 0.2717\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2884e-05 - acc: 0.2267 - val_loss: 1.1430e-04 - val_acc: 0.2718\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2873e-05 - acc: 0.2488 - val_loss: 1.1655e-04 - val_acc: 0.2759\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2758e-05 - acc: 0.2587 - val_loss: 1.4960e-04 - val_acc: 0.2900\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 63s 48us/step - loss: 1.2430e-05 - acc: 0.3000 - val_loss: 1.4478e-04 - val_acc: 0.2952\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.2177e-05 - acc: 0.2538 - val_loss: 1.4628e-04 - val_acc: 0.3869\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                4050      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                390       \n",
      "=================================================================\n",
      "Total params: 5,715\n",
      "Trainable params: 5,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0738 - acc: 0.9673 - val_loss: 2.4493 - val_acc: 0.8472\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 60s 46us/step - loss: 0.0468 - acc: 0.9751 - val_loss: 2.4493 - val_acc: 0.8473\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0457 - acc: 0.9757 - val_loss: 2.4492 - val_acc: 0.8473\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0452 - acc: 0.9760 - val_loss: 2.4472 - val_acc: 0.8476\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0449 - acc: 0.9761 - val_loss: 2.4476 - val_acc: 0.8476\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0445 - acc: 0.9764 - val_loss: 2.4466 - val_acc: 0.8477\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0444 - acc: 0.9766 - val_loss: 2.4465 - val_acc: 0.8479\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 0.0443 - acc: 0.9767 - val_loss: 2.4470 - val_acc: 0.8477\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0441 - acc: 0.9768 - val_loss: 2.4468 - val_acc: 0.8478\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0437 - acc: 0.9771 - val_loss: 2.4462 - val_acc: 0.8480\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0432 - acc: 0.9773 - val_loss: 2.4458 - val_acc: 0.8480\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0429 - acc: 0.9774 - val_loss: 2.4461 - val_acc: 0.8480\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0428 - acc: 0.9774 - val_loss: 2.4466 - val_acc: 0.8479\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0427 - acc: 0.9774 - val_loss: 2.4464 - val_acc: 0.8476\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0426 - acc: 0.9775 - val_loss: 2.4461 - val_acc: 0.8480\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0426 - acc: 0.9775 - val_loss: 2.4460 - val_acc: 0.8477\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 60s 47us/step - loss: 0.0425 - acc: 0.9775 - val_loss: 2.4463 - val_acc: 0.8476\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0426 - acc: 0.9776 - val_loss: 2.4462 - val_acc: 0.8480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 0.0423 - acc: 0.9776 - val_loss: 2.4458 - val_acc: 0.8481\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0428 - acc: 0.9776 - val_loss: 2.4453 - val_acc: 0.8482\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0422 - acc: 0.9777 - val_loss: 2.4459 - val_acc: 0.8480\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 63s 48us/step - loss: 0.0422 - acc: 0.9776 - val_loss: 2.4460 - val_acc: 0.8481\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0421 - acc: 0.9777 - val_loss: 2.4454 - val_acc: 0.8482\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0421 - acc: 0.9777 - val_loss: 2.4455 - val_acc: 0.8481\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0419 - acc: 0.9777 - val_loss: 2.4461 - val_acc: 0.8481\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0422 - acc: 0.9776 - val_loss: 2.4460 - val_acc: 0.8481\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0422 - acc: 0.9777 - val_loss: 2.4458 - val_acc: 0.8481\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0420 - acc: 0.9777 - val_loss: 2.4459 - val_acc: 0.8480\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0419 - acc: 0.9777 - val_loss: 2.4461 - val_acc: 0.8481\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 0.0419 - acc: 0.9777 - val_loss: 2.4459 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▎     | 17/40 [18:28:27<25:51:43, 4047.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                2160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4880      \n",
      "=================================================================\n",
      "Total params: 14,035\n",
      "Trainable params: 14,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "=================================================================\n",
      "Total params: 6,995\n",
      "Trainable params: 6,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 0.0057 - acc: 0.3112 - val_loss: 0.0015 - val_acc: 0.3628\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 0.0015 - acc: 0.4196 - val_loss: 0.0015 - val_acc: 0.3592\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 9.3517e-04 - acc: 0.2854 - val_loss: 0.0010 - val_acc: 0.2556\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 7.8164e-04 - acc: 0.2669 - val_loss: 9.8011e-04 - val_acc: 0.2578\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 7.5535e-04 - acc: 0.2580 - val_loss: 9.6274e-04 - val_acc: 0.2571\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 3.0800e-04 - acc: 0.2953 - val_loss: 2.0094e-04 - val_acc: 0.5411\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 5.3258e-05 - acc: 0.3379 - val_loss: 1.8868e-04 - val_acc: 0.2545\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 4.9056e-05 - acc: 0.3640 - val_loss: 1.8228e-04 - val_acc: 0.3287\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 4.6678e-05 - acc: 0.4752 - val_loss: 1.8215e-04 - val_acc: 0.5485\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 3.3449e-05 - acc: 0.4629 - val_loss: 1.4921e-04 - val_acc: 0.5508\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 2.4328e-05 - acc: 0.4850 - val_loss: 1.4776e-04 - val_acc: 0.5546\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 2.1972e-05 - acc: 0.5154 - val_loss: 1.4271e-04 - val_acc: 0.5628\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.8042e-05 - acc: 0.5357 - val_loss: 1.4115e-04 - val_acc: 0.5725\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.7090e-05 - acc: 0.5127 - val_loss: 1.3825e-04 - val_acc: 0.5846\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.6408e-05 - acc: 0.5165 - val_loss: 1.4609e-04 - val_acc: 0.5763\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.5856e-05 - acc: 0.4542 - val_loss: 1.4135e-04 - val_acc: 0.5795\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.5343e-05 - acc: 0.4917 - val_loss: 1.4542e-04 - val_acc: 0.5740\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.4866e-05 - acc: 0.4738 - val_loss: 1.4266e-04 - val_acc: 0.5768\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.4655e-05 - acc: 0.4706 - val_loss: 1.4067e-04 - val_acc: 0.5738\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.4303e-05 - acc: 0.4942 - val_loss: 1.3959e-04 - val_acc: 0.5768\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2135      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                540       \n",
      "=================================================================\n",
      "Total params: 7,535\n",
      "Trainable params: 7,535\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.6310 - acc: 0.8020 - val_loss: 2.2290 - val_acc: 0.8363\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.1293 - acc: 0.9579 - val_loss: 2.4314 - val_acc: 0.8433\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0718 - acc: 0.9704 - val_loss: 2.4404 - val_acc: 0.8457\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0590 - acc: 0.9730 - val_loss: 2.4506 - val_acc: 0.8462\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0547 - acc: 0.9736 - val_loss: 2.4529 - val_acc: 0.8465\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0526 - acc: 0.9739 - val_loss: 2.4531 - val_acc: 0.8465\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0512 - acc: 0.9743 - val_loss: 2.4519 - val_acc: 0.8468\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0502 - acc: 0.9746 - val_loss: 2.4512 - val_acc: 0.8469\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0494 - acc: 0.9749 - val_loss: 2.4511 - val_acc: 0.8468\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0489 - acc: 0.9750 - val_loss: 2.4515 - val_acc: 0.8470\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0484 - acc: 0.9752 - val_loss: 2.4509 - val_acc: 0.8471\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0480 - acc: 0.9754 - val_loss: 2.4506 - val_acc: 0.8471\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0477 - acc: 0.9754 - val_loss: 2.4513 - val_acc: 0.8470\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0474 - acc: 0.9755 - val_loss: 2.4503 - val_acc: 0.8472\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0472 - acc: 0.9756 - val_loss: 2.4503 - val_acc: 0.8472\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0470 - acc: 0.9755 - val_loss: 2.4497 - val_acc: 0.8472\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0468 - acc: 0.9757 - val_loss: 2.4495 - val_acc: 0.8473\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0467 - acc: 0.9757 - val_loss: 2.4504 - val_acc: 0.8472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0465 - acc: 0.9757 - val_loss: 2.4507 - val_acc: 0.8470\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0464 - acc: 0.9757 - val_loss: 2.4495 - val_acc: 0.8473\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0463 - acc: 0.9758 - val_loss: 2.4496 - val_acc: 0.8473\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0462 - acc: 0.9758 - val_loss: 2.4495 - val_acc: 0.8473\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0461 - acc: 0.9758 - val_loss: 2.4493 - val_acc: 0.8473\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0461 - acc: 0.9758 - val_loss: 2.4501 - val_acc: 0.8471\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0460 - acc: 0.9758 - val_loss: 2.4493 - val_acc: 0.8473\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0459 - acc: 0.9758 - val_loss: 2.4491 - val_acc: 0.8474\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0459 - acc: 0.9758 - val_loss: 2.4490 - val_acc: 0.8474\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0458 - acc: 0.9759 - val_loss: 2.4496 - val_acc: 0.8473\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0458 - acc: 0.9758 - val_loss: 2.4487 - val_acc: 0.8474\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0457 - acc: 0.9758 - val_loss: 2.4489 - val_acc: 0.8474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 45%|████▌     | 18/40 [18:43:09<18:56:00, 3098.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                2520      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 16,355\n",
      "Trainable params: 16,355\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2485      \n",
      "=================================================================\n",
      "Total params: 8,155\n",
      "Trainable params: 8,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 0.0031 - acc: 0.3108 - val_loss: 6.0891e-04 - val_acc: 0.3605\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 2.0908e-04 - acc: 0.2899 - val_loss: 4.9335e-04 - val_acc: 0.3488\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.4369e-04 - acc: 0.3797 - val_loss: 4.8858e-04 - val_acc: 0.3934\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.3775e-04 - acc: 0.3894 - val_loss: 4.6896e-04 - val_acc: 0.3887\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.2281e-04 - acc: 0.4303 - val_loss: 4.6013e-04 - val_acc: 0.4096\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.2073e-04 - acc: 0.4832 - val_loss: 4.5396e-04 - val_acc: 0.4364\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 6.7426e-05 - acc: 0.4344 - val_loss: 1.1903e-04 - val_acc: 0.3926\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.7189e-05 - acc: 0.3931 - val_loss: 1.1091e-04 - val_acc: 0.3950\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.5970e-05 - acc: 0.4494 - val_loss: 1.1218e-04 - val_acc: 0.3715\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.5030e-05 - acc: 0.4455 - val_loss: 1.0086e-04 - val_acc: 0.4020\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.4199e-05 - acc: 0.4440 - val_loss: 1.0166e-04 - val_acc: 0.3882\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.3383e-05 - acc: 0.4698 - val_loss: 9.4761e-05 - val_acc: 0.3897\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.2855e-05 - acc: 0.3893 - val_loss: 9.4972e-05 - val_acc: 0.3830\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.2507e-05 - acc: 0.3670 - val_loss: 9.3510e-05 - val_acc: 0.3303\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.2172e-05 - acc: 0.3631 - val_loss: 9.5480e-05 - val_acc: 0.3660\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.1852e-05 - acc: 0.3657 - val_loss: 9.2595e-05 - val_acc: 0.3417\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.1725e-05 - acc: 0.3505 - val_loss: 9.1204e-05 - val_acc: 0.3320\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.1421e-05 - acc: 0.3487 - val_loss: 9.0052e-05 - val_acc: 0.3249\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 19s 14us/step - loss: 1.1249e-05 - acc: 0.3396 - val_loss: 8.9382e-05 - val_acc: 0.3141\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 18s 14us/step - loss: 1.1063e-05 - acc: 0.3379 - val_loss: 8.8260e-05 - val_acc: 0.3061\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 35)                2485      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                540       \n",
      "=================================================================\n",
      "Total params: 8,695\n",
      "Trainable params: 8,695\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0720 - acc: 0.9701 - val_loss: 2.4761 - val_acc: 0.8453\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0593 - acc: 0.9746 - val_loss: 2.4832 - val_acc: 0.8448\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0579 - acc: 0.9754 - val_loss: 2.4824 - val_acc: 0.8450\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0574 - acc: 0.9758 - val_loss: 2.4824 - val_acc: 0.8453\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0571 - acc: 0.9757 - val_loss: 2.4799 - val_acc: 0.8457\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0574 - acc: 0.9761 - val_loss: 2.4811 - val_acc: 0.8455\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0570 - acc: 0.9762 - val_loss: 2.4802 - val_acc: 0.8457\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0564 - acc: 0.9762 - val_loss: 2.4811 - val_acc: 0.8457\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0573 - acc: 0.9763 - val_loss: 2.4818 - val_acc: 0.8454\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0563 - acc: 0.9763 - val_loss: 2.4839 - val_acc: 0.8431\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0575 - acc: 0.9758 - val_loss: 2.4800 - val_acc: 0.8457\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0585 - acc: 0.9761 - val_loss: 2.4807 - val_acc: 0.8457\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 17s 14us/step - loss: 0.0570 - acc: 0.9764 - val_loss: 2.4827 - val_acc: 0.8456\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0608 - acc: 0.9761 - val_loss: 2.4813 - val_acc: 0.8457\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0609 - acc: 0.9763 - val_loss: 2.4842 - val_acc: 0.8455\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0565 - acc: 0.9765 - val_loss: 2.4833 - val_acc: 0.8456\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0620 - acc: 0.9763 - val_loss: 2.4799 - val_acc: 0.8457\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0608 - acc: 0.9762 - val_loss: 2.4847 - val_acc: 0.8454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0642 - acc: 0.9760 - val_loss: 2.4979 - val_acc: 0.8445\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0630 - acc: 0.9761 - val_loss: 2.4818 - val_acc: 0.8456\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 16s 13us/step - loss: 0.0660 - acc: 0.9761 - val_loss: 2.4805 - val_acc: 0.8458\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0637 - acc: 0.9763 - val_loss: 2.4813 - val_acc: 0.8455\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0621 - acc: 0.9763 - val_loss: 2.4806 - val_acc: 0.8459\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0579 - acc: 0.9765 - val_loss: 2.4804 - val_acc: 0.8459\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0753 - acc: 0.9754 - val_loss: 2.4845 - val_acc: 0.8456\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0673 - acc: 0.9760 - val_loss: 2.4863 - val_acc: 0.8454\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0720 - acc: 0.9757 - val_loss: 2.4812 - val_acc: 0.8458\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0877 - acc: 0.9745 - val_loss: 2.4851 - val_acc: 0.8454\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0628 - acc: 0.9762 - val_loss: 2.4836 - val_acc: 0.8458\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 17s 13us/step - loss: 0.0552 - acc: 0.9767 - val_loss: 2.4818 - val_acc: 0.8457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 19/40 [18:57:54<14:11:56, 2434.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                2130      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 70)                2170      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                5680      \n",
      "=================================================================\n",
      "Total params: 15,650\n",
      "Trainable params: 15,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                2130      \n",
      "=================================================================\n",
      "Total params: 7,800\n",
      "Trainable params: 7,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 4.0947e-04 - acc: 0.2441 - val_loss: 1.4264e-04 - val_acc: 0.2951\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 2.0978e-05 - acc: 0.2823 - val_loss: 1.2832e-04 - val_acc: 0.3362\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 119s 91us/step - loss: 1.7985e-05 - acc: 0.2558 - val_loss: 1.1301e-04 - val_acc: 0.3846\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.6293e-05 - acc: 0.2430 - val_loss: 1.1050e-04 - val_acc: 0.2794\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.5029e-05 - acc: 0.3120 - val_loss: 9.9852e-05 - val_acc: 0.4124\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.4668e-05 - acc: 0.3220 - val_loss: 9.4657e-05 - val_acc: 0.2943\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.4700e-05 - acc: 0.3453 - val_loss: 1.0542e-04 - val_acc: 0.6573\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3856e-05 - acc: 0.3487 - val_loss: 1.0354e-04 - val_acc: 0.2831\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3783e-05 - acc: 0.4296 - val_loss: 1.1436e-04 - val_acc: 0.3322\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3615e-05 - acc: 0.4266 - val_loss: 1.0028e-04 - val_acc: 0.4928\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3563e-05 - acc: 0.4994 - val_loss: 1.1088e-04 - val_acc: 0.4143\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3451e-05 - acc: 0.5705 - val_loss: 1.1509e-04 - val_acc: 0.4014\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.2630e-05 - acc: 0.5124 - val_loss: 1.1054e-04 - val_acc: 0.4276\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.3020e-05 - acc: 0.5954 - val_loss: 1.1057e-04 - val_acc: 0.4451\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.2850e-05 - acc: 0.6226 - val_loss: 1.0217e-04 - val_acc: 0.8100\n",
      "Epoch 16/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.2902e-05 - acc: 0.6152 - val_loss: 1.0318e-04 - val_acc: 0.4549\n",
      "Epoch 17/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.2441e-05 - acc: 0.5630 - val_loss: 1.0751e-04 - val_acc: 0.4534\n",
      "Epoch 18/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.1848e-05 - acc: 0.5567 - val_loss: 1.1263e-04 - val_acc: 0.3769\n",
      "Epoch 19/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.2053e-05 - acc: 0.5636 - val_loss: 1.1433e-04 - val_acc: 0.3827\n",
      "Epoch 20/20\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 1.1846e-05 - acc: 0.5472 - val_loss: 9.9589e-05 - val_acc: 0.3879\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 70)                5670      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                2130      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                465       \n",
      "=================================================================\n",
      "Total params: 8,265\n",
      "Trainable params: 8,265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.1489 - acc: 0.9488 - val_loss: 2.4510 - val_acc: 0.8467\n",
      "Epoch 2/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0494 - acc: 0.9749 - val_loss: 2.4504 - val_acc: 0.8468\n",
      "Epoch 3/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0467 - acc: 0.9756 - val_loss: 2.4491 - val_acc: 0.8474\n",
      "Epoch 4/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0457 - acc: 0.9760 - val_loss: 2.4495 - val_acc: 0.8474\n",
      "Epoch 5/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0451 - acc: 0.9762 - val_loss: 2.4489 - val_acc: 0.8474\n",
      "Epoch 6/30\n",
      "1295452/1295452 [==============================] - 118s 91us/step - loss: 0.0447 - acc: 0.9764 - val_loss: 2.4489 - val_acc: 0.8475\n",
      "Epoch 7/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0444 - acc: 0.9765 - val_loss: 2.4487 - val_acc: 0.8474\n",
      "Epoch 8/30\n",
      "1295452/1295452 [==============================] - 120s 92us/step - loss: 0.0442 - acc: 0.9765 - val_loss: 2.4482 - val_acc: 0.8475\n",
      "Epoch 9/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0440 - acc: 0.9766 - val_loss: 2.4484 - val_acc: 0.8474\n",
      "Epoch 10/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0439 - acc: 0.9767 - val_loss: 2.4476 - val_acc: 0.8475\n",
      "Epoch 11/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.0438 - acc: 0.9767 - val_loss: 2.4473 - val_acc: 0.8476\n",
      "Epoch 12/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0437 - acc: 0.9767 - val_loss: 2.4479 - val_acc: 0.8475\n",
      "Epoch 13/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0437 - acc: 0.9767 - val_loss: 2.4471 - val_acc: 0.8476\n",
      "Epoch 14/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0436 - acc: 0.9768 - val_loss: 2.4483 - val_acc: 0.8470\n",
      "Epoch 15/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0435 - acc: 0.9768 - val_loss: 2.4468 - val_acc: 0.8478\n",
      "Epoch 16/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0434 - acc: 0.9769 - val_loss: 2.4472 - val_acc: 0.8477\n",
      "Epoch 17/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0433 - acc: 0.9770 - val_loss: 2.4472 - val_acc: 0.8476\n",
      "Epoch 18/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0433 - acc: 0.9770 - val_loss: 2.4473 - val_acc: 0.8476\n",
      "Epoch 19/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0432 - acc: 0.9771 - val_loss: 2.4464 - val_acc: 0.8479\n",
      "Epoch 20/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0431 - acc: 0.9771 - val_loss: 2.4477 - val_acc: 0.8476\n",
      "Epoch 21/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0430 - acc: 0.9772 - val_loss: 2.4470 - val_acc: 0.8476\n",
      "Epoch 22/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0429 - acc: 0.9773 - val_loss: 2.4472 - val_acc: 0.8477\n",
      "Epoch 23/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0428 - acc: 0.9773 - val_loss: 2.4470 - val_acc: 0.8478\n",
      "Epoch 24/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.0428 - acc: 0.9774 - val_loss: 2.4471 - val_acc: 0.8478\n",
      "Epoch 25/30\n",
      "1295452/1295452 [==============================] - 122s 94us/step - loss: 0.0427 - acc: 0.9774 - val_loss: 2.4465 - val_acc: 0.8479\n",
      "Epoch 26/30\n",
      "1295452/1295452 [==============================] - 121s 93us/step - loss: 0.0427 - acc: 0.9775 - val_loss: 2.4467 - val_acc: 0.8479\n",
      "Epoch 27/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0426 - acc: 0.9775 - val_loss: 2.4475 - val_acc: 0.8473\n",
      "Epoch 28/30\n",
      "1295452/1295452 [==============================] - 121s 94us/step - loss: 0.0425 - acc: 0.9775 - val_loss: 2.4471 - val_acc: 0.8477\n",
      "Epoch 29/30\n",
      "1295452/1295452 [==============================] - 120s 93us/step - loss: 0.0425 - acc: 0.9776 - val_loss: 2.4467 - val_acc: 0.8478\n",
      "Epoch 30/30\n",
      "1295452/1295452 [==============================] - 119s 92us/step - loss: 0.0425 - acc: 0.9776 - val_loss: 2.4466 - val_acc: 0.8479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 20/40 [20:37:42<19:26:43, 3500.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation= <keras.layers.advanced_activations.LeakyReLU object at 0x000001A4597FCEF0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1525      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                1560      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 80)                4880      \n",
      "=================================================================\n",
      "Total params: 12,825\n",
      "Trainable params: 12,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "80\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 60)                4860      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 25)                1525      \n",
      "=================================================================\n",
      "Total params: 6,385\n",
      "Trainable params: 6,385\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1295452 samples, validate on 323863 samples\n",
      "Epoch 1/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 9.7049e-04 - acc: 0.2931 - val_loss: 1.7651e-04 - val_acc: 0.3192\n",
      "Epoch 2/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 2.8266e-05 - acc: 0.2911 - val_loss: 1.5202e-04 - val_acc: 0.3043\n",
      "Epoch 3/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 2.1727e-05 - acc: 0.2770 - val_loss: 1.5913e-04 - val_acc: 0.2932\n",
      "Epoch 4/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.8961e-05 - acc: 0.2607 - val_loss: 1.7738e-04 - val_acc: 0.3212\n",
      "Epoch 5/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.7250e-05 - acc: 0.2465 - val_loss: 1.5702e-04 - val_acc: 0.3291\n",
      "Epoch 6/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.6682e-05 - acc: 0.2774 - val_loss: 1.6363e-04 - val_acc: 0.3614\n",
      "Epoch 7/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.5644e-05 - acc: 0.2676 - val_loss: 1.6131e-04 - val_acc: 0.3192\n",
      "Epoch 8/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.5025e-05 - acc: 0.2901 - val_loss: 1.3631e-04 - val_acc: 0.3738\n",
      "Epoch 9/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.4672e-05 - acc: 0.3071 - val_loss: 1.3025e-04 - val_acc: 0.3278\n",
      "Epoch 10/20\n",
      "1295452/1295452 [==============================] - 62s 48us/step - loss: 1.4499e-05 - acc: 0.3039 - val_loss: 1.2341e-04 - val_acc: 0.3471\n",
      "Epoch 11/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.4070e-05 - acc: 0.2816 - val_loss: 1.2170e-04 - val_acc: 0.3832\n",
      "Epoch 12/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.3649e-05 - acc: 0.3114 - val_loss: 1.1661e-04 - val_acc: 0.3184\n",
      "Epoch 13/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.3065e-05 - acc: 0.2832 - val_loss: 1.1122e-04 - val_acc: 0.3152\n",
      "Epoch 14/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.3013e-05 - acc: 0.3033 - val_loss: 1.1754e-04 - val_acc: 0.3241\n",
      "Epoch 15/20\n",
      "1295452/1295452 [==============================] - 61s 47us/step - loss: 1.2664e-05 - acc: 0.2863 - val_loss: 1.1773e-04 - val_acc: 0.3168\n",
      "Epoch 16/20\n",
      "1105984/1295452 [========================>.....] - ETA: 8s - loss: 1.2589e-05 - acc: 0.3462"
     ]
    }
   ],
   "source": [
    "\n",
    "t = ta.Scan(x, y, p, dnn, experiment_no='2',grid_downsample=0.05,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ta.Reporting(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.best_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
